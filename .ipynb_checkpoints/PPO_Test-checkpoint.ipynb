{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "import os\n",
    "os.environ[\"NGSIM_DIR\"] = \"/home/surender/Downloads/NGSIM\"\n",
    "os.environ[\"OPENDD_DIR\"] = \"/home/surender/Downloads/openDD\"\n",
    "os.environ[\"CARLA_PATH\"] = \"/home/surender/Downloads/carlaOld\"\n",
    "import sys\n",
    "#sys.path.append('/home/surender/Downloads/CARLA_0.9.9.4/PythonAPI/carla/dist')\n",
    "import carla\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "from carla_real_traffic_scenarios.carla_maps import CarlaMaps\n",
    "from carla_real_traffic_scenarios.ngsim import NGSimDatasets, DatasetMode\n",
    "from carla_real_traffic_scenarios.ngsim.scenario import NGSimLaneChangeScenario\n",
    "from carla_real_traffic_scenarios.opendd.scenario import OpenDDScenario\n",
    "from carla_real_traffic_scenarios.reward import RewardType\n",
    "from carla_real_traffic_scenarios.scenario import Scenario\n",
    "\n",
    "from carla_birdeye_view import BirdViewProducer, BirdViewCropType, PixelDimensions\n",
    "from PIL import Image\n",
    "#from IPython.display import clear_output, Image, display, HTML\n",
    "import cv2\n",
    "\n",
    "%matplotlib tk\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdl = MobileNet(input_shape=(186, 150, 3),include_top=False,weights=\"imagenet\",pooling=max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to : GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "    \n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controller import VehiclePIDController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"Helper to flatten a tensor.\"\"\"\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "'''\n",
    "class Normal(nn.Module):\n",
    "    \"\"\"A module that builds a Diagonal Gaussian distribution from means.\n",
    "    Standard deviations are learned parameters in this module.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_outputs):\n",
    "        super().__init__()\n",
    "        # initial variance is e^0 = 1\n",
    "        self.stds = nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "    def forward(self, x):\n",
    "        dist = torch.distributions.Normal(loc=x, scale=self.stds.exp())\n",
    "\n",
    "        # By default we get the probability of sampling each dimension of the\n",
    "        # distribution. The full probability is the product of these, or\n",
    "        # the sum since we're working with log probabilities.\n",
    "        # So overwrite the log_prob function to handle this for us\n",
    "        dist.old_log_prob = dist.log_prob\n",
    "        dist.log_prob = lambda x: dist.old_log_prob(x).sum(-1)\n",
    "\n",
    "        return dist\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,num_channels=3):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 16, kernel_size=1, stride=1),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.l1 = nn.ConvTranspose2d(16, 16, kernel_size = 8, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.ConvTranspose2d(16, 32, kernel_size = 8, stride=2)\n",
    "        self.l3 = nn.ConvTranspose2d(32, 3, kernel_size = 8, stride=1)\n",
    "        self.l4 = nn.ConvTranspose2d(3,3,kernel_size = 20,stride = 5)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        #x = self.flatten(x)\n",
    "        #print(x.shape)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.l3(x)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.l4(x)\n",
    "        \n",
    "        x = self.sig(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "        \n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init,hidden_size = 512,num_channels = 5):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 16, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4,2),\n",
    "            nn.Flatten(),\n",
    "            #nn.AvgPool2d(7),\n",
    "            #nn.Flatten(),\n",
    "            nn.Linear(2240, action_dim),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(512, 256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(256,64),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,action_dim),\n",
    "            nn.Tanh()\n",
    "        \n",
    "        )\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 16, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4,2),\n",
    "            nn.Flatten(),\n",
    "            #nn.AvgPool2d(7),\n",
    "            #nn.Flatten(),\n",
    "            nn.Linear(2240, 1),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(512, 256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(256,64),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,action_dim),\n",
    "            nn.Tanh()\n",
    "            #nn.AvgPool2d(7),\n",
    "            #nn.Flatten(),\n",
    "            #nn.Linear(1280, 1),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(512, 256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(256,64),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,1),\n",
    "            #nn.Tanh()\n",
    "        \n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, kernel_size=8, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(4,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            #nn.Conv2d(128, 256, kernel_size=4, stride=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124416, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,action_dim),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, kernel_size=8, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(4,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            #nn.Conv2d(128, 256, kernel_size=4, stride=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124416, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,1),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        #self.l1 = nn.Conv2d(num_channels, 32, kernel_size=4, stride=2)\n",
    "        #self.l2 = nn.Conv2d(32, 16, kernel_size=4, stride=2)\n",
    "        #self.l3 = nn.Conv2d(16, 8, kernel_size=3, stride=1)\n",
    "        #self.p = nn.MaxPool2d(2, 2)\n",
    "        '''\n",
    "        ''''\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 16, kernel_size=4, stride=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1),\n",
    "            \n",
    "            #nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.l1 = nn.ConvTranspose2d(16, 16, kernel_size = 8, stride=4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.ConvTranspose2d(16, 32, kernel_size = 8, stride=1)\n",
    "        self.l3 = nn.ConvTranspose2d(32, 3, kernel_size = 8, stride=2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.layer1 = nn.Conv2d(num_channels, 32, kernel_size=8, stride=4)\n",
    "        self.relu = nn.ReLU();\n",
    "        self.layer2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.layer3 = nn.Conv2d(64, 32, kernel_size=3, stride=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer4 = nn.Linear(9120,512)\n",
    "        self.actol = nn.Linear(512, action_dim)\n",
    "        self.acto = nn.Tanh()\n",
    "        self.crit = nn.Linear(512, 1)\n",
    "        '''\n",
    "        #self.actor = nn.Sequential(self.main,nn.Linear(hidden_size, action_dim))\n",
    "        #self.critic = nn.Sequential(self.main_two,nn.Linear(hidden_size, 1))\n",
    "        '''\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Tanh()\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "        '''\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    def AutoEncoder(self,x):\n",
    "        '''\n",
    "        x = self.encoder(x)\n",
    "        print(x.shape)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.l3(x)\n",
    "        x = self.sig(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        print(x.shape)\n",
    "        x = self.l1(x)\n",
    "        print(x.shape)\n",
    "        x = self.p(x)\n",
    "        print(x.shape)\n",
    "        x = self.l2(x)\n",
    "        print(x.shape)\n",
    "        x = self.p(x)\n",
    "        print(x.shape)\n",
    "        x = self.l3(x)\n",
    "        print(x.shape)\n",
    "        x = self.p(x)\n",
    "        print(x.shape)\n",
    "        '''\n",
    "        #x = self.encoder(x)\n",
    "        #return x\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "        '''\n",
    "        print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer4(x)\n",
    "        print(x.shape)\n",
    "        a = self.actol(x)\n",
    "        a = self.acto(a)\n",
    "        v = self.crit(x)\n",
    "        return a,v\n",
    "        '''\n",
    "        \n",
    "    def backward(self, x):\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            #x = self.main(state)\n",
    "            action_mean = self.actor(state)\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        \n",
    "        return action.detach(), action_logprob.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            '''\n",
    "            if len(state.shape) == 3:\n",
    "                state = state.reshape((1,5,186,150))\n",
    "            '''\n",
    "            #x = self.main(state)\n",
    "            #print(state.shape)\n",
    "            action_mean = self.actor(state)\n",
    "            #print(action_mean.shape)\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            #print(action_var,action_var.shape)\n",
    "            \n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            #print(cov_mat)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "            #print(dist)\n",
    "            # for single action continuous environments\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "        #print(state_values,action_mean)\n",
    "        return action_logprobs, state_values, dist_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "        self.entropy_c = 0.01\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        \n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        \n",
    "                        {'params': self.policy.critic.parameters(),'lr': lr_critic}\n",
    "                        \n",
    "                    ])\n",
    "        self.optimizer2 = torch.optim.Adam([\n",
    "            {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "        ])\n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        \n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        #print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                #print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                pass\n",
    "                #print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "\n",
    "        #print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "            \n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        #print(self.buffer.rewards)\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "        #print(\"I\",rewards)\n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        #print(rewards,rewards.mean(),rewards.std(unbiased = False))\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std(unbiased = False) + 1e-7)\n",
    "        #print(rewards)\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "\n",
    "        \n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "            #print(state_values)\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "            \n",
    "            #state_values = torch.\n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "            #print(ratios)\n",
    "            # Finding Spurrogate Loss\n",
    "            advantages = rewards - state_values.detach()   \n",
    "            #print(rewards)\n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "            #print(state_values)\n",
    "            #print(state_values.shape)\n",
    "            # final loss of clipped objective PPO\n",
    "            #print(rewards.shape,state_values.shape)\n",
    "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
    "            #print(surr1,surr2,state_values,rewards,dist_entropy,loss)\n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "            #self.optimizer2.step()\n",
    "        if self.entropy_c > 0.001:\n",
    "            self.entropy_c -= 0.0001\n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_timestep = 1000     # update policy every n timesteps\n",
    "K_epochs = 40               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.999                # discount factor\n",
    "\n",
    "lr_actor = 0.0003       # learning rate for actor network\n",
    "lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "random_seed = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ngsim_scenario(client: carla.Client, data_mode = \"train\") -> Scenario:\n",
    "    data_dir = os.environ.get(\"NGSIM_DIR\")\n",
    "    #data_dir = os.listdir('/home/surender/Downloads/NGSIM')\n",
    "    assert data_dir, \"Path to the directory with NGSIM dataset is required\"\n",
    "    ngsim_map = NGSimDatasets.list()\n",
    "    ngsim_dataset = ngsim_map[1]\n",
    "    client.load_world(ngsim_dataset.carla_map.level_path)\n",
    "    if data_mode == \"train\":\n",
    "        return NGSimLaneChangeScenario(\n",
    "            ngsim_dataset,\n",
    "            dataset_mode=DatasetMode.TRAIN,\n",
    "            data_dir=data_dir,\n",
    "            reward_type=RewardType.DENSE,\n",
    "            client=client,\n",
    "        )\n",
    "    else:\n",
    "        return NGSimLaneChangeScenario(\n",
    "            ngsim_dataset,\n",
    "            dataset_mode=DatasetMode.VALIDATION,\n",
    "            data_dir=data_dir,\n",
    "            reward_type=RewardType.DENSE,\n",
    "            client=client,\n",
    "        )\n",
    "\n",
    "'''\n",
    "def prepare_opendd_scenario(client: carla.Client) -> Scenario:\n",
    "    data_dir = os.environ.get(\"OPENDD_DIR\")\n",
    "    assert data_dir, \"Path to the directory with openDD dataset is required\"\n",
    "    maps = [\"rdb1\", \"rdb2\", \"rdb3\", \"rdb4\", \"rdb5\", \"rdb6\", \"rdb7\"]\n",
    "    map_name = random.choice(maps)\n",
    "    carla_map = getattr(CarlaMaps, map_name.upper())\n",
    "    client.load_world(carla_map.level_path)\n",
    "    return OpenDDScenario(\n",
    "        client,\n",
    "        dataset_dir=data_dir,\n",
    "        dataset_mode=DatasetMode.TRAIN,\n",
    "        reward_type=RewardType.DENSE,\n",
    "        place_name=map_name,\n",
    "    )\n",
    "\n",
    "'''\n",
    "def prepare_ego_vehicle(world: carla.World) -> carla.Actor:\n",
    "    car_blueprint = world.get_blueprint_library().find(\"vehicle.audi.a2\")\n",
    "\n",
    "    # This will allow external scripts like manual_control.py or no_rendering_mode.py\n",
    "    # from the official CARLA examples to take control over the ego agent\n",
    "    car_blueprint.set_attribute(\"role_name\", \"hero\")\n",
    "\n",
    "    # spawn points doesnt matter - scenario sets up position in reset\n",
    "    ego_vehicle = world.spawn_actor(\n",
    "        car_blueprint, carla.Transform(carla.Location(0, 0, 500), carla.Rotation())\n",
    "    )\n",
    "\n",
    "    assert ego_vehicle is not None, \"Ego vehicle could not be spawned\"\n",
    "\n",
    "    # Setup any car sensors you like, collect observations and then use them as input to your model\n",
    "    return ego_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_carla():\n",
    "    os.system(\"DISPLAY= /home/surender/Downloads/carlaOld/CarlaUE4.sh -benchmark -fps=10 -quality-level=Low -opengl -Resx=300 -Resy=300 -NoVSync \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_carla():\n",
    "    os.system(\"DISPLAY= /home/surender/Downloads/carlaOld/CarlaUE4.sh -benchmark -fps=5 -quality-level=Low -opengl -Resx=4 -Resy=4 -NoVSync\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "thp = threading.Thread(target = cmd_carla)\n",
    "thp.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost\"\n",
    "port = 2000\n",
    "client = carla.Client(host,port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.squeeze(torch.tensor([[1.4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    }
   ],
   "source": [
    "scenario = prepare_ngsim_scenario(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()\n",
    "spectator = world.get_spectator()\n",
    "ego_vehicle = prepare_ego_vehicle(world)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = world.get_settings()\n",
    "settings.no_rendering_mode = True\n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_img(img):\n",
    "    global input_data,current_frame\n",
    "    c_img = img\n",
    "    #print(img.frame)\n",
    "    array = np.frombuffer(img.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    #print(array.shape)\n",
    "    array = np.reshape(array, (img.height, img.width, 4)) # RGBA format\n",
    "    array = array[:, :, :3] #  Take only RGB\n",
    "    #print(array.shape)\n",
    "    #plt.imshow(array)\n",
    "    \n",
    "    img = Image.fromarray(array)\n",
    "    \n",
    "    #print(img)\n",
    "    img = img.resize((320,320), Image.ANTIALIAS)\n",
    "    #print(img)\n",
    "    input_data = np.array(img)\n",
    "    current_frame = c_img.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "cam_bp.set_attribute(\"image_size_x\",str(320))\n",
    "cam_bp.set_attribute(\"image_size_y\",str(320))\n",
    "cam_bp.set_attribute(\"fov\",str(100))\n",
    "cam_location = carla.Location(2,0,1)\n",
    "cam_rotation = carla.Rotation(0,0,0)\n",
    "cam_transform = carla.Transform(cam_location,cam_rotation)\n",
    "ego_front_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid)\n",
    "#self.rgb_front_listener = ego_cam\n",
    "ego_front_cam.listen(lambda image: check_img(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla_real_traffic_scenarios.artificial_lane_change.scenario import ArtificialLaneChangeScenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#als = ArtificialLaneChangeScenario(client = client,cmd_for_changing_lane=r.chauffeur_cmd,speed_range_token=\"HIGHWAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scenario.reset(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScenarioStepResult(chauffeur_cmd=<ChauffeurCommand.CHANGE_LANE_LEFT: 4>, reward=0.0, done=False, info={'ngsim_dataset': {'road': 'US101', 'timeslice': '0805am-0820am', 'frame': 752, 'dataset_mode': 'TRAIN'}, 'scenario_data': {'ego_veh': <carla.libcarla.Vehicle object at 0x7f997c3f32d0>, 'original_veh_transform': <carla.libcarla.Transform object at 0x7f997c298170>, 'original_to_ego_distance': 1.8672974109649658}, 'reward_type': 'DENSE', 'on_start_lane': True, 'on_target_lane': False, 'is_junction': False, 'alignment_errors': 'track=0.00m yaw=0.00rad', 'target_alignment_counter': 0})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = VehiclePIDController(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pid.run_step(30,r.info[\"scenario_data\"][\"original_veh_transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.apply_control(carla.VehicleControl(throttle=0.2, steer=-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.chauffeur_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_v = r.info[\"scenario_data\"][\"ego_veh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_v.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.info[\"scenario_data\"][\"original_veh_transform\"].location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = prepare_ngsim_scenario(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()\n",
    "spectator = world.get_spectator()\n",
    "ego_vehicle = prepare_ego_vehicle(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.reset(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.x -= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.y += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def way_cal(ego_vehicle,val,stabilize = False, actual_waypoint = None):\n",
    "    way = ego_vehicle.get_transform()\n",
    "    if (val == 0  or val ==1):\n",
    "        way.location.x += 100 \n",
    "        #s_clip_n = -0.15\n",
    "        #s_clip_p = 0.15\n",
    "        #t_clip_n = 0.4\n",
    "        #t_clip_p = 1.0\n",
    "        \n",
    "    if (val == 2 or val == 5):\n",
    "        way.location.x += 30\n",
    "        way.location.y += 7\n",
    "        #s_clip_n = 0.25\n",
    "        #s_clip_p = 0.8\n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.4\n",
    "\n",
    "    if (val == 3 or val == 4):\n",
    "        way.location.x += 30\n",
    "        way.location.y -= 7\n",
    "        #s_clip_n = -0.8\n",
    "        #s_clip_p = -0.25\n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.4\n",
    "    return way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngsim_dataset': {'road': 'US101',\n",
       "  'timeslice': '0750am-0805am',\n",
       "  'frame': 5225,\n",
       "  'dataset_mode': 'TRAIN'},\n",
       " 'scenario_data': {'ego_veh': <carla.libcarla.Vehicle at 0x7f997c3f32d0>,\n",
       "  'original_veh_transform': <carla.libcarla.Transform at 0x7f997c2074f0>,\n",
       "  'original_to_ego_distance': 1.9875487089157104},\n",
       " 'reward_type': 'DENSE',\n",
       " 'on_start_lane': True,\n",
       " 'on_target_lane': False,\n",
       " 'is_junction': False,\n",
       " 'alignment_errors': 'track=0.00m yaw=0.00rad',\n",
       " 'target_alignment_counter': 0,\n",
       " 'prev_episode_done_cause': 'collision'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.19999999999999996 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.20000000000000007 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.10000000000000009 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.19999999999999996 False ChauffeurCommand.LANE_FOLLOW\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.19999999999999996 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.10000000000000009 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.10000000000000009 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.10000000000000009 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "-1.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.19999999999999996 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.20000000000000007 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.20000000000000007 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.19999999999999996 False ChauffeurCommand.LANE_FOLLOW\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.19999999999999996 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.10000000000000009 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.2 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.20000000000000007 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.20000000000000007 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.2 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.19999999999999996 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.20000000000000007 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.20000000000000007 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.19999999999999996 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.30000000000000004 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.19999999999999996 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.3 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.9 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.2 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.09999999999999998 False ChauffeurCommand.LANE_FOLLOW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7999999999999999 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.10000000000000003 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.10000000000000009 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.10000000000000009 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.2 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.19999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.3 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.2 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.30000000000000004 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.LANE_FOLLOW\n",
      "-0.30000000000000004 False ChauffeurCommand.LANE_FOLLOW\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.9 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.2 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.09999999999999998 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.9 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.9 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.9 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.8 False ChauffeurCommand.LANE_FOLLOW\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.1 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.19999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.2 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.19999999999999996 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.20000000000000007 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.20000000000000007 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-0.2999999999999998 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1 False ChauffeurCommand.LANE_FOLLOW\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.1 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-0.9 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_RIGHT\n",
      "0.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n",
      "-1.0 False ChauffeurCommand.CHANGE_LANE_LEFT\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    scenario.reset(ego_vehicle)\n",
    "    done = False\n",
    "    c = world.tick()\n",
    "    way = ego_vehicle.get_transform()\n",
    "    cmd_buffer = [0]\n",
    "    stab = False\n",
    "    aw = None\n",
    "    speed = 40\n",
    "    while not done:\n",
    "        pid = VehiclePIDController(ego_vehicle)\n",
    "        k = pid.run_step(speed,way)\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=k.throttle, steer=k.steer, brake = k.brake))\n",
    "        r = scenario.step(ego_vehicle)\n",
    "        print(r.reward,done,r.chauffeur_cmd)\n",
    "        #way = scenario._target_lane_waypoint.transform\n",
    "        way = r.info[\"scenario_data\"][\"original_veh_transform\"]\n",
    "        cmd_buffer.append(r.chauffeur_cmd.value)\n",
    "\n",
    "        if len(cmd_buffer)>5:\n",
    "            if sum(cmd_buffer[-5:]) == 0 or sum(cmd_buffer[-5:]) == 5:\n",
    "                way = scenario._target_lane_waypoint.transform\n",
    "                way.location.x += 50\n",
    "                speed = 40\n",
    "\n",
    "        birdview = birdview_producer.produce(\n",
    "\n",
    "                agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "                )\n",
    "        rgb = BirdViewProducer.as_rgb(birdview)\n",
    "        cv2.imshow('Frame',rgb)\n",
    "        done = r.done\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "        c = world.tick()\n",
    "    cv2.destroyAllWindows()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )\n",
    "rgb = BirdViewProducer.as_rgb(birdview)\n",
    "cv2.imshow('Frame',rgb)\n",
    "\n",
    "if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PPO(1,2,lr_actor,lr_critic,gamma,K_epochs,eps_clip,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.load(\"Model_CHK4.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEncoder(3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ae(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape((3,320,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape((320,320,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview_producer = BirdViewProducer(\n",
    "    client,  # carla.Client\n",
    "    target_size=PixelDimensions(width=150, height=186),\n",
    "    pixels_per_meter=4,\n",
    "    crop_type=BirdViewCropType.FRONT_AREA_ONLY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = BirdViewProducer.as_rgb(birdview)\n",
    "cv2.imshow('Frame',rgb)\n",
    "\n",
    "if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = birdview[0].reshape(1,186,150)\n",
    "a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "a = np.append(a,birdview[4].reshape(1,186,150),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a[1,:,:] = birdview[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(1,5,186,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.append(a,birdview[3].reshape(1,224,224),axis=0)\n",
    "a = np.append(a,birdview[4].reshape(1,224,224),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(1,3,224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = rgb.reshape(1,186,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.append(inp, rgb.reshape(1,186,150,3),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_var = torch.full((2,), 0.9 * 0.9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.FloatTensor(a).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mean = p.policy.actor(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = torch.diag(action_var).unsqueeze(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = MultivariateNormal(action_mean, cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = dist.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_logprob = dist.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = mdl(inp).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(a.shape[0],20480).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reshape(b.shape[0],20480).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y - ego_vehicle.get_location().y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.x - ego_vehicle.get_location().x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ego_vehicle.get_velocity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ego_vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )\n",
    "rgb = BirdViewProducer.as_rgb(birdview)\n",
    "cv2.imshow('Frame',rgb)\n",
    "\n",
    "if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[0]) #Full Road Greyed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[1])  #Lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[2]) #Centerlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[3])#Other vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[4])# Ego agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = birdview[:5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = in_data.reshape((1,5,186,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.actor(state.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.forward(torch.FloatTensor(in_data).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.actor.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    state = torch.FloatTensor(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = p.policy.AutoEncoder(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEncoder(3).to(device)\n",
    "optimizer = torch.optim.Adam([\n",
    "                        {'params': ae.parameters(), 'lr': 0.003}\n",
    "])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.cat((state,state), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del inp_tensor,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =  state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "min_batch_size = 32\n",
    "inp_tensor = state\n",
    "ep_list = []\n",
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    step = 0\n",
    "    scenario.reset(ego_vehicle)\n",
    "    c = world.tick()\n",
    "    done = False\n",
    "    total_r = 0\n",
    "    val = 0\n",
    "    \n",
    "    while not done:\n",
    "        in_data = input_data.reshape((1,3,320,320))\n",
    "        with torch.no_grad():\n",
    "            st = torch.FloatTensor(in_data)\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=0.5))\n",
    "        try:\n",
    "            cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "        except:\n",
    "            break\n",
    "        c = world.tick()\n",
    "        inp_tensor = torch.cat((inp_tensor,st),0)\n",
    "        del st\n",
    "        if inp_tensor.shape[0] >= min_batch_size:\n",
    "            break\n",
    "        step += 1\n",
    "    if inp_tensor.shape[0] >= min_batch_size:\n",
    "            optimizer.zero_grad()\n",
    "            A = inp_tensor/255.\n",
    "            #A -= A.min(1, keepdim=True)[0]\n",
    "            #A /= A.max(1, keepdim=True)[0]\n",
    "            inp_tensor = A\n",
    "            outputs = ae(inp_tensor.to(device))\n",
    "            loss = criterion(outputs, inp_tensor.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"EPOCH:\",epoch,\"LOSS:\",loss.item())\n",
    "            ep_list.append(epoch)\n",
    "            loss_list.append(loss.item())\n",
    "            del inp_tensor,outputs,A\n",
    "            inp_tensor = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE_loss = [ep_list,loss_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_loss_1 = [ep_list,loss_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"MSE1.pkl\",'wb')\n",
    "pickle.dump(MSE_loss_1,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(0,1)\n",
    "plt.plot(ep_list,loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = state.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_img = in_data.reshape((3,320,320)).reshape((320,320,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out =ae(state.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oupp = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_img = oupp.reshape((3,320,320)).reshape((320,320,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(o_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward_list = []\n",
    "epoch_list = []\n",
    "step_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "mobilenet = models.mobilenet_v2(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    in_data = torch.FloatTensor(in_data).to(device)\n",
    "in_data = mobilenet.features(in_data).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PID_Controller(cmd,e_v,steer):\n",
    "    speed_limit = 60\n",
    "    min_speed = 10\n",
    "    v = e_v.get_velocity()\n",
    "    kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "    if kmh > speed_limit:\n",
    "        throttle = 0.1 + + random.random()/8\n",
    "        brake = 0.9\n",
    "    elif kmh < min_speed:\n",
    "        throttle = 0.4 + random.random()/8\n",
    "        brake = 0.0\n",
    "    else:\n",
    "        throttle = 0.1 + random.random()/8\n",
    "        brake = 0\n",
    "    \n",
    "    if (val == 0  or val ==1):\n",
    "        #Go Straight\n",
    "        \n",
    "        if abs(steer)> 0.1:\n",
    "            \n",
    "            throttle = 0.1 +  random.random()/8\n",
    "            \n",
    "                \n",
    "            brake = (kmh-10)/50\n",
    "            \n",
    "        else:\n",
    "            throttle = (60-kmh)/50 + random.random()/8\n",
    "            brake = 0\n",
    "            \n",
    "        \n",
    "        #s_clip_n = -0.15\n",
    "        #s_clip_p = 0.15\n",
    "        #t_clip_n = 0.4\n",
    "        #t_clip_p = 1.0\n",
    "\n",
    "    if (val == 2 or val == 5):\n",
    "        # Go right\n",
    "        \n",
    "        if steer < 0:\n",
    "            brake = (kmh-10)/50\n",
    "            throttle = 0.1\n",
    "        if steer > 0:\n",
    "            throttle = (60-kmh)/50 + random.random()/8\n",
    "            brake = 0\n",
    "        #s_clip_n = 0.25\n",
    "        #s_clip_p = 0.6\n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.4\n",
    "\n",
    "    if (val == 3 or val == 4):\n",
    "        # Go Left\n",
    "        if steer < 0 :\n",
    "            throttle = (60-kmh)/50 + random.random()/8\n",
    "            brake = 0\n",
    "        if steer > 0 :\n",
    "            brake = (kmh-10)/50\n",
    "            throttle = 0.1\n",
    "        #s_clip_n = -0.6\n",
    "        #s_clip_p = -0.25\n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.4\n",
    "    if throttle <= 0:\n",
    "        throttle = 0.05 + random.random()/50\n",
    "    if throttle >= 0.4:\n",
    "        throttle = 0.4 + random.random()/8\n",
    "    if brake < 0:\n",
    "        brake = 0\n",
    "    if brake >= 1:\n",
    "        brake = 0.9\n",
    "    return throttle,brake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "freq = 5\n",
    "freq_n = 3\n",
    "update_freq = 500\n",
    "decay_freq = 1000\n",
    "decay_c = 1000\n",
    "#val = 0\n",
    "min_r_avg = -1\n",
    "steer_w = 1\n",
    "min_steer_w = 0\n",
    "steer_decay = 0.1\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    step = 0\n",
    "    del ego_vehicle\n",
    "    scenario.close()\n",
    "    scenario = prepare_ngsim_scenario(client)\n",
    "    \n",
    "    #time.sleep(3)\n",
    "    world = client.get_world()\n",
    "    spectator = world.get_spectator()\n",
    "    #client.reload_world()\n",
    "    \n",
    "    ego_vehicle = prepare_ego_vehicle(world)\n",
    "    \n",
    "    scenario.reset(ego_vehicle)\n",
    "    c = world.tick()\n",
    "    #way = scenario._target_lane_waypoint.transform\n",
    "    way = ego_vehicle.get_transform()\n",
    "    #c = world.tick()\n",
    "    done = False\n",
    "    total_r = 0\n",
    "    val = 0\n",
    "    \n",
    "    \n",
    "    t_clip_n = 0.0\n",
    "    t_clip_p = 1.0\n",
    "    \n",
    "    s_clip_n = -1.0\n",
    "    s_clip_p = 1.0\n",
    "    cmd_buffer = [0]\n",
    "    yaw_buffer = [0]\n",
    "    while not done:\n",
    "        '''\n",
    "        while True:\n",
    "            #print(current_frame,c)\n",
    "            if current_frame >= c:\n",
    "                #print(current_frame,c)\n",
    "                break\n",
    "        '''\n",
    "        birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )\n",
    "        a = birdview[0].reshape(1,186,150)\n",
    "        a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "        a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "        a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "        a = np.append(a,birdview[4].reshape(1,186,150),axis=0)\n",
    "        #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "        #rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "        in_data = a.reshape(1,5,186,150)\n",
    "        #in_data = rgb.reshape(1,3,186,150)\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            in_data = torch.FloatTensor(in_data).to(device)\n",
    "            in_data = mobilenet.features(in_data).detach().cpu().numpy()\n",
    "        '''\n",
    "        #in_data = mdl(in_data).numpy()\n",
    "        #in_data = in_data.reshape(in_data.shape[0],62720)\n",
    "        #in_data = in_data.reshape((1,5,186,150))\n",
    "        #in_data = input_data.reshape((1,3,320,320))\n",
    "        #print(in_data.shape)\n",
    "        action = p.select_action(in_data)\n",
    "        #print(action)\n",
    "        \n",
    "        '''\n",
    "        if (val == 0  or val ==1):\n",
    "            s_clip_n = -0.15\n",
    "            s_clip_p = 0.15\n",
    "            t_clip_n = 0.4\n",
    "            t_clip_p = 1.0\n",
    "        \n",
    "        if (val == 2 or val == 5):\n",
    "            s_clip_n = 0.25\n",
    "            s_clip_p = 0.8\n",
    "            t_clip_n = 0.0\n",
    "            t_clip_p = 0.4\n",
    "        \n",
    "        if (val == 3 or val == 4):\n",
    "            s_clip_n = -0.8\n",
    "            s_clip_p = -0.25\n",
    "            t_clip_n = 0.0\n",
    "            t_clip_p = 0.4\n",
    "        '''\n",
    "            \n",
    "        \n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.7\n",
    "\n",
    "        #s_clip_n = -0.6\n",
    "        #s_clip_p = 0.6  \n",
    "        steer = action[1]\n",
    "        _speed = np.clip(action[0], -1,1)\n",
    "        speed = ((_speed + 1)/2)*50 + 10\n",
    "        \n",
    "        '''\n",
    "        brake = 0\n",
    "        throttle = 0\n",
    "        if action[0] <0:\n",
    "            brake = action[0]\n",
    "            throttle = 0\n",
    "        else:\n",
    "            throttle = action[0]\n",
    "            brake = 0\n",
    "        '''\n",
    "        '''\n",
    "        if epoch > 400:\n",
    "            if (val == 0  or val ==1):\n",
    "                s_clip_n = -0.15\n",
    "                s_clip_p = 0.15\n",
    "                t_clip_n = 0.4\n",
    "                t_clip_p = 1.0\n",
    "\n",
    "            if (val == 2 or val == 5):\n",
    "                s_clip_n = 0.25\n",
    "                s_clip_p = 0.6\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "\n",
    "            if (val == 3 or val == 4):\n",
    "                s_clip_n = -0.6\n",
    "                s_clip_p = -0.25\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "        '''\n",
    "        #if epoch < 20:\n",
    "        #print(throttle,steer,brake)\n",
    "        pid = VehiclePIDController(ego_vehicle)\n",
    "        k = pid.run_step(speed,way)\n",
    "        throttle = k.throttle\n",
    "        brake = k.brake\n",
    "        if epoch < 500:\n",
    "            avg_steer = (k.steer + steer_w * steer)/(steer_w + 1)\n",
    "        else:\n",
    "            avg_steer = steer\n",
    "        avg_steer = steer\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(avg_steer, s_clip_n, s_clip_p),brake=brake))\n",
    "        \n",
    "        #ego_vehicle.apply_control(carla.VehicleControl(throttle=np.clip(throttle, t_clip_n, t_clip_p), steer=np.clip(action[1], s_clip_n, s_clip_p)))#,brake=np.clip(brake, 0.0, 1.0)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "        '''\n",
    "        if reward < 0 :\n",
    "            reward = -0.1\n",
    "        '''\n",
    "        \n",
    "        val = cmd.value\n",
    "        cmd_buffer.append(val)\n",
    "        yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "        if len(cmd_buffer) > 10:\n",
    "            if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and abs(sum(yaw_buffer[-5:])/5)<=10:\n",
    "                reward = 1\n",
    "                done = True\n",
    "        \n",
    "        if reward >=0.9:\n",
    "            print(\"Close to win\")\n",
    "        if reward >= 1:\n",
    "            print(\"Its a win\")\n",
    "            #p.save(\"WinModel\"+str(epoch)+\".mdl\")\n",
    "        way = _[\"scenario_data\"][\"original_veh_transform\"]\n",
    "        #way = scenario._target_lane_waypoint.transform  \n",
    "        \n",
    "        \n",
    "        #print(action[0],action[1])\n",
    "        #print(done)\n",
    "        #if done:\n",
    "        #    print(_)\n",
    "        #print(_)\n",
    "        '''\n",
    "        if (val == 0  or val ==1):\n",
    "            if action[0] > 0.0:\n",
    "                reward += 0.01\n",
    "            if action[1] < 0.1 and action[1]> -0.1:\n",
    "                reward += 0.01\n",
    "                \n",
    "\n",
    "        if (val == 2 or val == 5):\n",
    "            if action[0] <0.1:\n",
    "                reward += 0.01\n",
    "            if action[1] > 0.0:\n",
    "                reward += 0.01\n",
    "\n",
    "        if (val == 3 or val == 4):\n",
    "            if action[0] < 0.1:\n",
    "                reward += 0.01\n",
    "            if action[1] < 0.0:\n",
    "                reward += 0.01\n",
    "        '''\n",
    "        #reward += step\n",
    "        '''\n",
    "        v = ego_vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "        \n",
    "        if kmh < 60 & kmh > 0.2:\n",
    "            #done = False\n",
    "            reward += 1 #-1\n",
    "            # Reward lighter steering when moving\n",
    "            if np.abs(action[1]) < 0.3:\n",
    "                reward += 1\n",
    "            elif np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "                reward -= 0.1\n",
    "            elif np.abs(action[1]) >= 0.9:\n",
    "                reward -= 0.2\n",
    "        elif kmh < 0.2:\n",
    "            reward -= 0.1\n",
    "        else:\n",
    "            #print(\"Maybe never\")\n",
    "            reward += 0.01\n",
    "            if np.abs(action[1]) < 0.3:\n",
    "                reward += 0.12\n",
    "            # Reduce score for heavy steering\n",
    "            if np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "                reward -= 0.17\n",
    "            elif np.abs(action[1]) >= 0.9:\n",
    "                reward -= 0.21\n",
    "        '''\n",
    "        '''\n",
    "        rgb = BirdViewProducer.as_rgb(birdview)\n",
    "        cv2.imshow('Frame',rgb)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        '''\n",
    "        p.buffer.rewards.append(reward)\n",
    "        p.buffer.is_terminals.append(done)\n",
    "        \n",
    "        total_r += reward\n",
    "        step += 1\n",
    "        \n",
    "        '''\n",
    "        if step % freq ==0 :\n",
    "            print(step)\n",
    "            p.update()\n",
    "        \n",
    "        if step % freq_n == 0:\n",
    "            p.decay_action_std(0.05,0.1)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        world.tick()\n",
    "    #total_r += step/10\n",
    "    if epoch > 50:\n",
    "        \n",
    "        if sum(total_reward_list[-50:])/len(total_reward_list[-50:]) > min_r_avg or sum(step_list) > decay_freq:\n",
    "            decay_freq += decay_c\n",
    "            #decay_c -= 50\n",
    "            print(\"Decaying:\",p.action_std)\n",
    "            p.decay_action_std(0.01,0.1)\n",
    "            \n",
    "            min_r_avg = sum(total_reward_list[-50:])/len(total_reward_list[-50:])\n",
    "    if len(p.buffer.states)> update_freq:\n",
    "            print(steer,avg_steer,throttle,brake,steer_w)\n",
    "            print(\"Update with batches:\",len(p.buffer.states))\n",
    "            p.update()\n",
    "            if steer_w > min_steer_w +0.1:\n",
    "                steer_w -= steer_decay\n",
    "\n",
    "    else:\n",
    "            print(total_r,epoch,step)\n",
    "            total_reward_list.append(total_r)\n",
    "            epoch_list.append(epoch)\n",
    "            step_list.append(step)\n",
    "            continue\n",
    "    #except Exception as e:\n",
    "        #print(\"Error:\",e)\n",
    "        #pass\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    print(total_r,epoch,step)\n",
    "    total_reward_list.append(total_r)\n",
    "    epoch_list.append(epoch)\n",
    "    step_list.append(step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decaying:\",p.action_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_['scenario_data']['original_to_ego_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_reward = []\n",
    "val_success = []\n",
    "for i in range(50):\n",
    "    t_clip_n = 0.0\n",
    "    t_clip_p = 1.0\n",
    "\n",
    "    s_clip_n = -1.0\n",
    "    s_clip_p = 1.0\n",
    "\n",
    "    step = 0\n",
    "    scenario = prepare_ngsim_scenario(client,\"Val\")\n",
    "    world = client.get_world()\n",
    "    spectator = world.get_spectator()\n",
    "    ego_vehicle = prepare_ego_vehicle(world)\n",
    "\n",
    "    scenario.reset(ego_vehicle)\n",
    "    c = world.tick()\n",
    "    way = ego_vehicle.get_transform()\n",
    "    done = False\n",
    "    reward = 0\n",
    "    val = 0\n",
    "    cmd_buffer = [0]\n",
    "    yaw_buffer = [0]\n",
    "    while not done:\n",
    "\n",
    "            birdview = birdview_producer.produce(\n",
    "                agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "                )\n",
    "            a = birdview[0].reshape(1,186,150)\n",
    "            a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "            a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "            a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "            a = np.append(a,birdview[4].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "            #rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "            in_data = a.reshape(1,5,186,150)\n",
    "\n",
    "            action = p.select_action(in_data)\n",
    "\n",
    "            steer = action[1]\n",
    "            _speed = np.clip(action[0], -1,1)\n",
    "            speed = ((_speed + 1)/2)*50 + 10\n",
    "\n",
    "\n",
    "\n",
    "            pid = VehiclePIDController(ego_vehicle)\n",
    "            k = pid.run_step(speed,way)\n",
    "            throttle = k.throttle\n",
    "            brake = k.brake\n",
    "\n",
    "            avg_steer = steer\n",
    "            ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(avg_steer, s_clip_n, s_clip_p),brake=brake))\n",
    "\n",
    "            #ego_vehicle.apply_control(carla.VehicleControl(throttle=np.clip(throttle, t_clip_n, t_clip_p), steer=np.clip(action[1], s_clip_n, s_clip_p)))#,brake=np.clip(brake, 0.0, 1.0)))\n",
    "\n",
    "\n",
    "\n",
    "            cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "            '''\n",
    "            if reward < 0 :\n",
    "                reward = -0.1\n",
    "            '''\n",
    "\n",
    "\n",
    "\n",
    "            print(reward, cmd, _['scenario_data']['original_to_ego_distance'], throttle,steer)\n",
    "\n",
    "            val = cmd.value\n",
    "            cmd_buffer.append(val)\n",
    "            yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "            if len(cmd_buffer) > 10:\n",
    "                if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and abs(sum(yaw_buffer[-5:])/5)<=10:\n",
    "                    reward = 1\n",
    "                    done = True\n",
    "\n",
    "            if reward >=0.9:\n",
    "                print(\"Close to win\")\n",
    "            if reward >= 1:\n",
    "                print(\"Its a win\")\n",
    "                #p.save(\"WinModel\"+str(epoch)+\".mdl\")\n",
    "            way = _[\"scenario_data\"][\"original_veh_transform\"]\n",
    "            #way = scenario._target_lane_waypoint.transform \n",
    "            '''\n",
    "            rgb = BirdViewProducer.as_rgb(birdview)\n",
    "            cv2.imshow('Frame',rgb)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            '''\n",
    "            c = world.tick()\n",
    "    if reward >0.9:\n",
    "        val_reward.append(reward)\n",
    "        val_success.append(1)\n",
    "    else:\n",
    "        val_reward.append(reward)\n",
    "        val_success.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_['on_target_lane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(val_success)/len(val_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_transform().rotation.yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_['scenario_data']['original_veh_transform'].rotation.yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.load(\"Model_CHK_TorchEasy.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.action_std = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.decay_action_std(0.01,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.action_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(2.5e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.reset(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle = prepare_ego_vehicle(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.apply_control(carla.VehicleControl(throttle=0.7, steer=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = [epoch_list,total_reward_list,step_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"History00.pkl\",'wb')\n",
    "pickle.dump(History,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(\"Model_Best.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = epoch_list[500:]\n",
    "total_reward_list = total_reward_list[500:]\n",
    "step_list = step_list[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(-2,1)\n",
    "plt.plot(epoch_list,total_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "320*320*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = input_data.reshape((1,3,320,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.buffer.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.buffer.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = glob.glob('Hi/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = {}\n",
    "for i in l:\n",
    "    f = open(i,'rb')\n",
    "    s = pickle.load(f)\n",
    "    f.close()\n",
    "    n = i.split('/')[1]\n",
    "    n = n.split('.')[0]\n",
    "    n = n.split('_')\n",
    "    if n[2] in hist.keys():\n",
    "        pass\n",
    "    else:\n",
    "        hist[n[2]] = {}\n",
    "    hist[n[2]][n[1]] = s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('w','2000') in hist.keys():\n",
    "    print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list_0 = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted([int(x) for x in hist['0'].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted([int(x) for x in hist['0'].keys()]):\n",
    "    epoch_list_0 += hist['0'][str(i)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['0']['500'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_list_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list_0 = []\n",
    "\n",
    "for i in sorted([int(x) for x in hist['0'].keys()]):\n",
    "    reward_list_0 += hist['0'][str(i)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list_0 = []\n",
    "for i in sorted([int(x) for x in hist['0'].keys()]):\n",
    "    step_list_0 += hist['0'][str(i)][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list_1 = []\n",
    "for i in sorted([int(x) for x in hist['1'].keys()]):\n",
    "    epoch_list_1 += hist['1'][str(i)][0]\n",
    "reward_list_1 = []\n",
    "for i in sorted([int(x) for x in hist['1'].keys()]):\n",
    "    reward_list_1 += hist['1'][str(i)][1]\n",
    "step_list_1 = []\n",
    "for i in sorted([int(x) for x in hist['1'].keys()]):\n",
    "    step_list_1 += hist['1'][str(i)][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch_list = epoch_list_0 + [x + len(epoch_list_0) for x in epoch_list_1]\n",
    "final_reward_list = reward_list_0 + reward_list_1\n",
    "final_step_list = step_list_0 + step_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch_list = epoch_list_0\n",
    "final_reward_list = reward_list_0\n",
    "final_step_list = step_list_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_epoch_list))\n",
    "print(len(final_reward_list))\n",
    "len(final_step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Reward Sum\")\n",
    "plt.plot(final_epoch_list,final_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Step size\")\n",
    "plt.plot(final_epoch_list,final_step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(final_epoch_list).reshape(-1,1),np.array(final_reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(0,7000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(np.array(x).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = epoch_list\n",
    "y= total_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Rewards\")\n",
    "plt.ylim(-2.0,2.0)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.ylim(0.0,10.0)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"History_5500_1.pkl\",'rb')\n",
    "s = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = s[0]\n",
    "r = s[1]\n",
    "t = s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
