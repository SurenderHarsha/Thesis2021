{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NGSIM_DIR\"] = \"C:/Users/Surender Harsha/Downloads/NGSIM/NGSIM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal,Beta,Dirichlet\n",
    "from torch.distributions import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "import os\n",
    "#os.environ[\"NGSIM_DIR\"] = \"C:\\Users\\Surender Harsha\\Downloads\\NGSIM\\NGSIM\"\n",
    "#os.environ[\"NGSIM_DIR\"] = \"\"\n",
    "#os.environ[\"OPENDD_DIR\"] = \"/home/surender/Downloads/openDD\"\n",
    "#os.environ[\"CARLA_PATH\"] = \"/home/surender/Downloads/carlaOld\"\n",
    "import sys\n",
    "#sys.path.append('/home/surender/Downloads/CARLA_0.9.9.4/PythonAPI/carla/dist')\n",
    "import carla\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "from carla_real_traffic_scenarios.carla_maps import CarlaMaps\n",
    "from carla_real_traffic_scenarios.ngsim import NGSimDatasets, DatasetMode\n",
    "from carla_real_traffic_scenarios.ngsim.scenario import NGSimLaneChangeScenario\n",
    "from carla_real_traffic_scenarios.opendd.scenario import OpenDDScenario\n",
    "from carla_real_traffic_scenarios.reward import RewardType\n",
    "from carla_real_traffic_scenarios.scenario import Scenario\n",
    "\n",
    "from carla_birdeye_view import BirdViewProducer, BirdViewCropType, PixelDimensions\n",
    "from PIL import Image\n",
    "#from IPython.display import clear_output, Image, display, HTML\n",
    "import cv2\n",
    "\n",
    "%matplotlib tk\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import math\n",
    "#import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdl = MobileNet(input_shape=(186, 150, 3),include_top=False,weights=\"imagenet\",pooling=max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to : NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    \n",
    "    \n",
    "    print(\"Device set to : cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.helper = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "    \n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]\n",
    "        del self.helper[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controller import VehiclePIDController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5000, -0.5000]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.ones(1, 2)*-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"Helper to flatten a tensor.\"\"\"\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "'''\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init,hidden_size = 512,num_channels = 5):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "        # 186x150\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 64, kernel_size=12, stride=2), #50x150\n",
    "            nn.BatchNorm2d(64), # 20x70\n",
    "            nn.MaxPool2d(4,2), # 9x34\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(128), #4x16\n",
    "            nn.MaxPool2d(2,1), \n",
    "            nn.ReLU(), # 3x15\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(256), #1x6\n",
    "            nn.MaxPool2d(1,6),\n",
    "            nn.ReLU(), #1x1\n",
    "            \n",
    "            #nn.ReLU(),\n",
    "            #nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            #nn.ReLU(),\n",
    "            #nn.AvgPool2d(7,7),\n",
    "            #nn.Flatten(),\n",
    "            #nn.AvgPool2d(7),\n",
    "            nn.Flatten(),\n",
    "            #nn.Linear(256, 256),\n",
    "            #nn.Dropout(0.4),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128)\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,action_dim),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "        nn.Linear(131, 64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU()\n",
    "        \n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            #nn.Linear(131, 64),\n",
    "            #nn.Dropout(0.4),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,64),\n",
    "            #nn.Dropout(0.4),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(64,action_dim),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.critic = nn.Sequential(\n",
    "            #nn.Linear(131, 64),\n",
    "            #nn.Dropout(0.4),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,64),\n",
    "            #nn.Dropout(0.4),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "            nn.Tanh()\n",
    "            #nn.Conv2d(num_channels, 16, kernel_size=8, stride=4),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            #nn.ReLU(),\n",
    "            #nn.AvgPool2d(7,7),\n",
    "            #nn.Flatten(),\n",
    "            #nn.AvgPool2d(7),\n",
    "            #nn.Flatten(),\n",
    "            #nn.Linear(1280, 256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(512, 256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(256,1),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,action_dim),\n",
    "            #nn.Tanh()\n",
    "            #nn.AvgPool2d(7),\n",
    "            #nn.Flatten(),\n",
    "            #nn.Linear(1280, 1),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(512, 256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(256,64),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64,1),\n",
    "            #nn.Tanh()\n",
    "        \n",
    "        )\n",
    "        '''\n",
    "        self.var = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(64,64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,2),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        '''\n",
    "        self.action_log_std = nn.Parameter(torch.ones(1, action_dim) * -0.5)\n",
    "        '''\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, kernel_size=8, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(4,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            #nn.Conv2d(128, 256, kernel_size=4, stride=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124416, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,action_dim),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, kernel_size=8, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(4,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2,1),\n",
    "            #nn.Conv2d(128, 256, kernel_size=4, stride=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            #nn.MaxPool2d(2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(124416, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,1),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        #self.l1 = nn.Conv2d(num_channels, 32, kernel_size=4, stride=2)\n",
    "        #self.l2 = nn.Conv2d(32, 16, kernel_size=4, stride=2)\n",
    "        #self.l3 = nn.Conv2d(16, 8, kernel_size=3, stride=1)\n",
    "        #self.p = nn.MaxPool2d(2, 2)\n",
    "        '''\n",
    "        ''''\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 16, kernel_size=4, stride=2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1),\n",
    "            \n",
    "            #nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.l1 = nn.ConvTranspose2d(16, 16, kernel_size = 8, stride=4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.ConvTranspose2d(16, 32, kernel_size = 8, stride=1)\n",
    "        self.l3 = nn.ConvTranspose2d(32, 3, kernel_size = 8, stride=2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.layer1 = nn.Conv2d(num_channels, 32, kernel_size=8, stride=4)\n",
    "        self.relu = nn.ReLU();\n",
    "        self.layer2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.layer3 = nn.Conv2d(64, 32, kernel_size=3, stride=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer4 = nn.Linear(9120,512)\n",
    "        self.actol = nn.Linear(512, action_dim)\n",
    "        self.acto = nn.Tanh()\n",
    "        self.crit = nn.Linear(512, 1)\n",
    "        '''\n",
    "        #self.actor = nn.Sequential(self.main,nn.Linear(hidden_size, action_dim))\n",
    "        #self.critic = nn.Sequential(self.main_two,nn.Linear(hidden_size, 1))\n",
    "        '''\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Tanh()\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "        '''\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            #del self.action_var\n",
    "            self.action_var = torch.full((self.action_dim,),new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    def AutoEncoder(self,x):\n",
    "        '''\n",
    "        x = self.encoder(x)\n",
    "        print(x.shape)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.l3(x)\n",
    "        x = self.sig(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        print(x.shape)\n",
    "        x = self.l1(x)\n",
    "        print(x.shape)\n",
    "        x = self.p(x)\n",
    "        print(x.shape)\n",
    "        x = self.l2(x)\n",
    "        print(x.shape)\n",
    "        x = self.p(x)\n",
    "        print(x.shape)\n",
    "        x = self.l3(x)\n",
    "        print(x.shape)\n",
    "        x = self.p(x)\n",
    "        print(x.shape)\n",
    "        '''\n",
    "        #x = self.encoder(x)\n",
    "        #return x\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "        '''\n",
    "        print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer4(x)\n",
    "        print(x.shape)\n",
    "        a = self.actol(x)\n",
    "        a = self.acto(a)\n",
    "        v = self.crit(x)\n",
    "        return a,v\n",
    "        '''\n",
    "        \n",
    "    def backward(self, x):\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def act(self, state,helper,val = False):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            #x = self.main(state)\n",
    "            inps1 = state\n",
    "            inps2 = helper\n",
    "            action_m = self.layer1(inps1)\n",
    "            #print(action_m,inps2,action_m.shape,inps2.shape)\n",
    "            inps = torch.cat((action_m,inps2),1)\n",
    "            x = self.layer2(inps)\n",
    "            action_mean = self.actor(x)\n",
    "            if val:\n",
    "                return action_mean.detach(),-1\n",
    "            action_log_std = self.action_log_std.expand_as(action_mean)\n",
    "            \n",
    "            #action_var = self.var(x) + 0.001\n",
    "            #action_std = self.std(state)\n",
    "            #print(action_std)\n",
    "            #self.set_action_std(torch.mean(action_std))\n",
    "            #print(action_mean,action_std)\n",
    "            #action_var = action_var.expand_as(action_mean)\n",
    "            #cov_mat = torch.diag_embed(action_var)\n",
    "            #dist = MultivariateNormal(action_mean,cov_mat)\n",
    "            #cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            #print(action_mean.view(1, ).data, action_var.view(1, ).data)\n",
    "            #dist = Beta(action_mean, action_var)\n",
    "            dist = Normal(action_mean,action_log_std.exp())\n",
    "        else:\n",
    "            inps1 = state[:,:-3]\n",
    "            inps2 = state[:,-3:]\n",
    "            action_m = self.layer1(inps1)\n",
    "            #print(action_m,inps2,action_m.shape,inps2.shape)\n",
    "            inps = torch.cat((action_m,inps2),1)\n",
    "            \n",
    "            action_probs = self.actor(inps)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        \n",
    "        action_logprob = dist.log_prob(action)\n",
    "        #action = action*2 - 1\n",
    "        \n",
    "        return action.detach(), action_logprob.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state,helper, action):\n",
    "        #print(\"NOTHING\")\n",
    "        if self.has_continuous_action_space:\n",
    "            '''\n",
    "            if len(state.shape) == 3:\n",
    "                state = state.reshape((1,5,186,150))\n",
    "            '''\n",
    "            #x = self.main(state)\n",
    "            #print(state.shape)\n",
    "            inps1 = state\n",
    "            inps2 = helper\n",
    "            action_m = self.layer1(inps1)\n",
    "            inps = torch.cat((action_m,inps2),1)\n",
    "            x = self.layer2(inps)\n",
    "            \n",
    "            action_mean = self.actor(x)\n",
    "            action_log_std = self.action_log_std.expand_as(action_mean)\n",
    "            #action_var = self.var(x) + 1\n",
    "            #action_std = self.std(state)\n",
    "            #print(action_std)\n",
    "            #print(torch.mean(action_std))\n",
    "            #self.set_action_std(torch.mean(action_std))\n",
    "            #var = torch.mean(action_std)\n",
    "            #print(action_mean.shape)\n",
    "            #print(action_mean.shape,action_var.shape)\n",
    "            #action_var = action_var.expand_as(action_mean)\n",
    "            #print(action_var,action_var.shape)\n",
    "            #print(action_mean.shape,action_var.shape)\n",
    "            #cov_mat = torch.diag_embed(action_var)\n",
    "            #print(cov_mat)\n",
    "            dist = Normal(action_mean,action_log_std.exp())\n",
    "            #dist = Beta(action_mean, action_var)\n",
    "            #print(action_mean.shape,cov_var.shape)\n",
    "            #dist = MultivariateNormal(action_mean,cov_mat)\n",
    "            #print(dist)\n",
    "            # for single action continuous environments\n",
    "            #if self.action_dim == 1:\n",
    "            #    action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            inps1 = state[:,:-3]\n",
    "            inps2 = state[:,-3:]\n",
    "            action_m = self.layer1(inps1)\n",
    "            inps = torch.cat((action_m,inps2),1)\n",
    "            #x = self.layer2(inps)\n",
    "            action_probs = self.actor(inps)\n",
    "            dist = Categorical(action_probs)\n",
    "        #action = (action + 1)/2\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        #print(action_logprobs.shape)\n",
    "        dist_entropy = dist.entropy()\n",
    "        inps1 = state\n",
    "        inps2 = helper\n",
    "        critic_m = self.layer1(inps1)\n",
    "        inps = torch.cat((critic_m,inps2),1)\n",
    "        #action_mean = self.actor(inps)\n",
    "        x = self.layer2(inps)\n",
    "        state_values = self.critic(x)\n",
    "        #print(state_values,action_mean)\n",
    "        return action_logprobs, state_values, dist_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8ce7148de2b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "for i in p.policy.action_log_std:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "        self.entropy_c = 0.01\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        \n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.layer1.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.layer2.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic},\n",
    "                        {'params': self.policy.action_log_std, 'lr': 0.01}\n",
    "                        \n",
    "                        \n",
    "                    ])\n",
    "        \n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        \n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        #print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                #print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                pass\n",
    "                #print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "\n",
    "        #print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state,val = False):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                helper = torch.FloatTensor(state[1]).to(device)\n",
    "                state = torch.FloatTensor(state[0]).to(device)\n",
    "                \n",
    "                action, action_logprob = self.policy_old.act(state,helper,val)\n",
    "            if not val:\n",
    "                self.buffer.states.append(state)\n",
    "                self.buffer.helper.append(helper)\n",
    "                self.buffer.actions.append(action)\n",
    "                self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "            \n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        #print(self.buffer.rewards)\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "        #print(\"I\",rewards)\n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        #print(rewards,rewards.mean(),rewards.std(unbiased = False))\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std(unbiased = False) + 1e-7)\n",
    "        #print(rewards)\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "        old_helper = torch.squeeze(torch.stack(self.buffer.helper, dim=0)).detach().to(device)\n",
    "        batch_size = 32\n",
    "        print(old_states.shape,old_actions.shape,old_logprobs.shape)\n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "            for index in BatchSampler(SubsetRandomSampler(range(len(self.buffer.states))), batch_size, False):\n",
    "            # Evaluating old actions and values\n",
    "                #print(index,old_actions[index],old_actions)\n",
    "                \n",
    "                logprobs, state_values, dist_entropy = self.policy.evaluate(old_states[index],old_helper[index], old_actions[index])\n",
    "                temp_size = logprobs.shape[0]\n",
    "                #print(state_values.shape)\n",
    "                #print(logprobs.shape,logprobs)\n",
    "                # match state_values tensor dimensions with rewards tensor\n",
    "                state_values = torch.squeeze(state_values)\n",
    "                #print(state_values.shape)\n",
    "                #state_values = torch.\n",
    "                # Finding the ratio (pi_theta / pi_theta__old)\n",
    "                ratios = torch.exp(logprobs - old_logprobs[index].detach())\n",
    "                #print(ratios)\n",
    "                # Finding Spurrogate Loss\n",
    "                #print(rewards[index].shape)\n",
    "                advantages = rewards[index] - state_values.detach()   \n",
    "                #print(rewards)\n",
    "                #print(ratios.shape,advantages.shape)\n",
    "                advantages = advantages.reshape(temp_size,1)\n",
    "                surr1 = ratios * advantages\n",
    "                surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "                #print(state_values)\n",
    "                #print(state_values.shape)\n",
    "                # final loss of clipped objective PPO\n",
    "                #print(rewards.shape,state_values.shape)\n",
    "                loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards[index]) - 0.01*dist_entropy\n",
    "                #print(surr1,surr2,state_values,rewards,dist_entropy,loss)\n",
    "                # take gradient step\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.mean().backward()\n",
    "                self.optimizer.step()\n",
    "            #self.optimizer2.step()\n",
    "        if self.entropy_c > 0.001:\n",
    "            self.entropy_c -= 0.0001\n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214589967405923001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_timestep = 1000     # update policy every n timesteps\n",
    "K_epochs = 100             # update policy for K epochs\n",
    "eps_clip = 0.1             # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.001       # learning rate for actor network\n",
    "lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "random_seed = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ngsim_scenario(client: carla.Client, data_mode = \"train\") -> Scenario:\n",
    "    data_dir = os.environ.get(\"NGSIM_DIR\")\n",
    "    #data_dir = os.listdir('/home/surender/Downloads/NGSIM')\n",
    "    assert data_dir, \"Path to the directory with NGSIM dataset is required\"\n",
    "    ngsim_map = NGSimDatasets.list()\n",
    "    ngsim_dataset = ngsim_map[1]\n",
    "    client.load_world(ngsim_dataset.carla_map.level_path)\n",
    "    if data_mode == \"train\":\n",
    "        return NGSimLaneChangeScenario(\n",
    "            ngsim_dataset,\n",
    "            dataset_mode=DatasetMode.TRAIN,\n",
    "            data_dir=data_dir,\n",
    "            reward_type=RewardType.DENSE,\n",
    "            client=client,\n",
    "        )\n",
    "    else:\n",
    "        return NGSimLaneChangeScenario(\n",
    "            ngsim_dataset,\n",
    "            dataset_mode=DatasetMode.VALIDATION,\n",
    "            data_dir=data_dir,\n",
    "            reward_type=RewardType.DENSE,\n",
    "            client=client,\n",
    "        )\n",
    "\n",
    "'''\n",
    "def prepare_opendd_scenario(client: carla.Client) -> Scenario:\n",
    "    data_dir = os.environ.get(\"OPENDD_DIR\")\n",
    "    assert data_dir, \"Path to the directory with openDD dataset is required\"\n",
    "    maps = [\"rdb1\", \"rdb2\", \"rdb3\", \"rdb4\", \"rdb5\", \"rdb6\", \"rdb7\"]\n",
    "    map_name = random.choice(maps)\n",
    "    carla_map = getattr(CarlaMaps, map_name.upper())\n",
    "    client.load_world(carla_map.level_path)\n",
    "    return OpenDDScenario(\n",
    "        client,\n",
    "        dataset_dir=data_dir,\n",
    "        dataset_mode=DatasetMode.TRAIN,\n",
    "        reward_type=RewardType.DENSE,\n",
    "        place_name=map_name,\n",
    "    )\n",
    "\n",
    "'''\n",
    "def prepare_ego_vehicle(world: carla.World) -> carla.Actor:\n",
    "    car_blueprint = world.get_blueprint_library().find(\"vehicle.audi.a2\")\n",
    "\n",
    "    # This will allow external scripts like manual_control.py or no_rendering_mode.py\n",
    "    # from the official CARLA examples to take control over the ego agent\n",
    "    car_blueprint.set_attribute(\"role_name\", \"hero\")\n",
    "\n",
    "    # spawn points doesnt matter - scenario sets up position in reset\n",
    "    ego_vehicle = world.spawn_actor(\n",
    "        car_blueprint, carla.Transform(carla.Location(0, 0, 500), carla.Rotation())\n",
    "    )\n",
    "\n",
    "    assert ego_vehicle is not None, \"Ego vehicle could not be spawned\"\n",
    "\n",
    "    # Setup any car sensors you like, collect observations and then use them as input to your model\n",
    "    return ego_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_carla():\n",
    "    os.system(\"singularity exec --nv /data/s4120310/Singularity.sif /bin/bash /home/carla/CarlaUE4.sh -opengl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_carla():\n",
    "    os.system(\"DISPLAY= /home/surender/Downloads/carlaOld/CarlaUE4.sh -benchmark -fps=10 -quality-level=Low -opengl -Resx=4 -Resy=4 -NoVSync\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "thp = threading.Thread(target = cmd_carla)\n",
    "thp.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thp.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost\"\n",
    "port = 2000\n",
    "client = carla.Client(host,port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.squeeze(torch.tensor([[1.4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(1,3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    }
   ],
   "source": [
    "scenario = prepare_ngsim_scenario(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()\n",
    "spectator = world.get_spectator()\n",
    "ego_vehicle = prepare_ego_vehicle(world)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = world.get_settings()\n",
    "settings.no_rendering_mode = True\n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.arange(64).reshape(32,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.diag(c).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.arange(64).reshape(32,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions.Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =Beta(b[1:].float(),c[1:].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c.expand_as(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.diag_embed(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1][1] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = MultivariateNormal(b.float(),a.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame = 0\n",
    "input_data = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_img(img):\n",
    "    global input_data,current_frame\n",
    "    c_img = img\n",
    "    #print(img.frame)\n",
    "    array = np.frombuffer(img.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    #print(array.shape)\n",
    "    array = np.reshape(array, (img.height, img.width, 4)) # RGBA format\n",
    "    array = array[:, :, :3] #  Take only RGB\n",
    "    #print(array.shape)\n",
    "    #plt.imshow(array)\n",
    "    \n",
    "    img = Image.fromarray(array)\n",
    "    \n",
    "    #print(img)\n",
    "    img = img.resize((320,320), Image.ANTIALIAS)\n",
    "    #print(img)\n",
    "    input_data = np.array(img)\n",
    "    current_frame = c_img.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "cam_bp.set_attribute(\"image_size_x\",str(320))\n",
    "cam_bp.set_attribute(\"image_size_y\",str(320))\n",
    "cam_bp.set_attribute(\"fov\",str(100))\n",
    "cam_location = carla.Location(2,0,1)\n",
    "cam_rotation = carla.Rotation(0,0,0)\n",
    "cam_transform = carla.Transform(cam_location,cam_rotation)\n",
    "ego_front_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid)\n",
    "#self.rgb_front_listener = ego_cam\n",
    "ego_front_cam.listen(lambda image: check_img(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla_real_traffic_scenarios.artificial_lane_change.scenario import ArtificialLaneChangeScenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#als = ArtificialLaneChangeScenario(client = client,cmd_for_changing_lane=r.chauffeur_cmd,speed_range_token=\"HIGHWAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(world.get_actors()):\n",
    "    i.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(world.get_actors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(world.get_actors()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = [[0., 0.], [-0.3,0.], [-0.15,0.], [0.25,0.], [0.5, 0.], [0.7, 0.],\n",
    "                [0., 0.25], [-0.3,0.25], [-0.15,0.25], [0.25,0.25], [0.5, 0.25], [0.7, 0.25],\n",
    "                [0., -0.25], [-0.3,-0.25], [-0.15,-0.25], [0.25,-0.25], [0.5, -0.25], [0.7, -0.25],\n",
    "                [0., 0.5], [-0.3,0.5], [-0.15,0.5], [0.25,0.5], [0.5, 0.5], [0.7, 0.5],\n",
    "                [0., -0.5], [-0.3,-0.5], [-0.15,-0.5], [0.25,-0.5], [0.5, -0.5], [0.7, -0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scenario.reset(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = scenario._veh.speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for veh in v:\n",
    "    if veh.id == scenario._lane_change.vehicle_id:\n",
    "        c = veh\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = VehiclePIDController(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pid.run_step(30,r.info[\"scenario_data\"][\"original_veh_transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.apply_control(carla.VehicleControl(throttle=0.4, steer=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_control().steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.chauffeur_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_v = r.info[\"scenario_data\"][\"ego_veh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_v.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.info[\"scenario_data\"][\"original_veh_transform\"].location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = prepare_ngsim_scenario(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()\n",
    "#spectator = world.get_spectator()\n",
    "ego_vehicle = prepare_ego_vehicle(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.reset(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.x -= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.y += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def way_cal(ego_vehicle,val,stabilize = False, actual_waypoint = None):\n",
    "    way = ego_vehicle.get_transform()\n",
    "    if (val == 0  or val ==1):\n",
    "        way.location.x += 100        \n",
    "    if (val == 2 or val == 5):\n",
    "        way.location.x += 30\n",
    "        way.location.y += 7\n",
    "    if (val == 3 or val == 4):\n",
    "        way.location.x += 30\n",
    "        way.location.y -= 7\n",
    "    return way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(world.get_actors())[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    #scenario.reset(ego_vehicle)\n",
    "    #client.apply_batch([carla.command.DestroyActor(x) for x in list(world.get_actors())])\n",
    "    #world.tick()\n",
    "    ids = list(world.get_actors())[0].id\n",
    "    carla.command.DestroyActor(ids)\n",
    "    world = client.get_world()\n",
    "    #spectator = world.get_spectator()\n",
    "    ego_vehicle = prepare_ego_vehicle(world)\n",
    "    scenario.reset(ego_vehicle)\n",
    "    done = False\n",
    "    c = world.tick()\n",
    "    way = ego_vehicle.get_transform()\n",
    "    cmd_buffer = [0]\n",
    "    stab = False\n",
    "    aw = None\n",
    "    speed = 40\n",
    "    while not done:\n",
    "        pid = VehiclePIDController(ego_vehicle)\n",
    "        speed = random.randint(30,50)\n",
    "        k = pid.run_step(speed,way)\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=k.throttle, steer=k.steer, brake = k.brake))\n",
    "        r = scenario.step(ego_vehicle)\n",
    "        print(r.reward,done,r.chauffeur_cmd)\n",
    "        #way = scenario._target_lane_waypoint.transform\n",
    "        way = r.info[\"scenario_data\"][\"original_veh_transform\"]\n",
    "        cmd_buffer.append(r.chauffeur_cmd.value)\n",
    "\n",
    "        if len(cmd_buffer)>5:\n",
    "            if sum(cmd_buffer[-5:]) == 0 or sum(cmd_buffer[-5:]) == 5:\n",
    "                way = scenario._target_lane_waypoint.transform\n",
    "                way.location.x += 50\n",
    "                speed = 40\n",
    "\n",
    "        birdview = birdview_producer.produce(\n",
    "\n",
    "                agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "                )\n",
    "        rgb = BirdViewProducer.as_rgb(birdview)\n",
    "        cv2.imshow('Frame',rgb)\n",
    "        done = r.done\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "        c = world.tick()\n",
    "    cv2.destroyAllWindows()\n",
    "    #time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )\n",
    "rgb = BirdViewProducer.as_rgb(birdview)\n",
    "cv2.imshow('Frame',rgb)\n",
    "\n",
    "if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PPO(1,2,lr_actor,lr_critic,gamma,K_epochs,eps_clip,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.load(\"Model_CHK4.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCritic(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(5, 64, kernel_size=(12, 12), stride=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): MaxPool2d(kernel_size=1, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU()\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (14): Dropout(p=0.4, inplace=False)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=131, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.4, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): Dropout(p=0.4, inplace=False)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(p.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in p.policy.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.orthogonal_(p.policy.layer1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        #print(\"DONE\",m.weight)\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        #print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.layer1.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.layer2.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.actor.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.critic.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.policy.layer1.apply(init_normal)\n",
    "#p.policy.layer2.apply(init_normal)#\n",
    "#p.policy.actor.apply(init_normal)\n",
    "#p.policy.critic.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.action_log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEncoder(3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ae(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape((3,320,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape((320,320,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview_producer = BirdViewProducer(\n",
    "    client,  # carla.Client\n",
    "    target_size=PixelDimensions(width=50, height=150),\n",
    "    pixels_per_meter=4\n",
    "    #crop_type=BirdViewCropType.FRONT_AREA_ONLY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = BirdViewProducer.as_rgb(birdview)\n",
    "cv2.imshow('Frame',rgb)\n",
    "\n",
    "if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rgb/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    a[:,:,i] = (a[:,:,i] - mn[i])/std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =rgb/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(1,5,50,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 50, 150)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.policy.layer1(in_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ins = torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    in_data = torch.FloatTensor(a).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = mobilenet(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = birdview[0].reshape(1,186,150)\n",
    "a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "a = np.append(a,birdview[4].reshape(1,186,150),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a[1,:,:] = birdview[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rgb.reshape(1,3,186,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.reshape(3,186,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.append(a,birdview[3].reshape(1,224,224),axis=0)\n",
    "a = np.append(a,birdview[4].reshape(1,224,224),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(1,5,186,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inps = torch.FloatTensor(a).to(device)\n",
    "    c = p.policy.layer1(inps)\n",
    "    #b = nn.Flatten()(c)\n",
    "    #d = nn.ReLU(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rgb.reshape(1,3,224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd =  a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = np.concatenate((in_data[0],inps)).reshape(1,1283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = [0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((a,inps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(inps).reshape(186,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xd = torch.FloatTensor(inputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.concatenate((a[0,:,:],inps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [a,np.array(inps).reshape(1,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(inputs,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.action_log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(a,inps,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = rgb.reshape(1,186,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.append(inp, rgb.reshape(1,186,150,3),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_var = torch.full((2,), 0.9 * 0.9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.FloatTensor(a).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mean = p.policy.actor(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_transform().rotation.yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "v_begin = ego_vehicle.get_transform().location\n",
    "v_end = v_begin + carla.Location(x=math.cos(math.radians(ego_vehicle.get_transform().rotation.yaw)),\n",
    "                                         y=math.sin(math.radians(ego_vehicle.get_transform().rotation.yaw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_end.x,v_end.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_begin.x,v_begin.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vec = np.array([v_end.x - v_begin.x, v_end.y - v_begin.y, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = torch.diag(action_var).unsqueeze(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = MultivariateNormal(action_mean, cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = dist.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_logprob = dist.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 0\n",
    "mn=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "#in_data = a.reshape(1,5,186,150)\n",
    "for i in range(3):\n",
    "    rgb[:,:,i] = (rgb[:,:,i] - mn[i])/std[i]\n",
    "in_data = rgb.reshape(1,3,224,224)\n",
    "\n",
    "with torch.no_grad():\n",
    "    in_data = torch.FloatTensor(in_data).to(device)\n",
    "    in_data = mobilenet.features(in_data)\n",
    "    in_data = nn.AvgPool2d(7,7)(in_data)\n",
    "    in_data = nn.Flatten()(in_data)\n",
    "    in_data = in_data.detach().cpu().numpy()\n",
    "#in_data = mdl(in_data).numpy()\n",
    "#in_data = in_data.reshape(in_data.shape[0],62720)\n",
    "#in_data = in_data.reshape((1,5,186,150))\n",
    "#in_data = input_data.reshape((1,3,320,320))\n",
    "#print(in_data.shape)\n",
    "if val == 0 or val == 1:\n",
    "    inps= [0,0,1]\n",
    "if val == 2 or val == 5:\n",
    "    inps = [0,1,0]\n",
    "if val == 4 or val ==3:\n",
    "    inps = [1,0,0]\n",
    "inps = np.array(inps)\n",
    "ap = np.concatenate((in_data[0],inps)).reshape(1,1283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    in_data = torch.FloatTensor(in_data).to(device)\n",
    "    c = mobilenet.classifier(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(c.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.classifier(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space[p.select_action(ap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = mdl(inp).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(a.shape[0],20480).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reshape(b.shape[0],20480).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y - ego_vehicle.get_location().y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.x - ego_vehicle.get_location().x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ego_vehicle.get_velocity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ego_vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )\n",
    "rgb = BirdViewProducer.as_rgb(birdview)\n",
    "cv2.imshow('Frame',rgb)\n",
    "\n",
    "if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[0]) #Full Road Greyed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[1])  #Lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[2]) #Centerlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[3])#Other vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(birdview[4])# Ego agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = birdview[:5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = in_data.reshape((1,5,186,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.actor(state.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.forward(torch.FloatTensor(in_data).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.policy.actor.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    state = torch.FloatTensor(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = p.policy.AutoEncoder(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEncoder(3).to(device)\n",
    "optimizer = torch.optim.Adam([\n",
    "                        {'params': ae.parameters(), 'lr': 0.003}\n",
    "])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.cat((state,state), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del inp_tensor,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =  state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "min_batch_size = 32\n",
    "inp_tensor = state\n",
    "ep_list = []\n",
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    step = 0\n",
    "    scenario.reset(ego_vehicle)\n",
    "    c = world.tick()\n",
    "    done = False\n",
    "    total_r = 0\n",
    "    val = 0\n",
    "    \n",
    "    while not done:\n",
    "        in_data = input_data.reshape((1,3,320,320))\n",
    "        with torch.no_grad():\n",
    "            st = torch.FloatTensor(in_data)\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=0.5))\n",
    "        try:\n",
    "            cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "        except:\n",
    "            break\n",
    "        c = world.tick()\n",
    "        inp_tensor = torch.cat((inp_tensor,st),0)\n",
    "        del st\n",
    "        if inp_tensor.shape[0] >= min_batch_size:\n",
    "            break\n",
    "        step += 1\n",
    "    if inp_tensor.shape[0] >= min_batch_size:\n",
    "            optimizer.zero_grad()\n",
    "            A = inp_tensor/255.\n",
    "            #A -= A.min(1, keepdim=True)[0]\n",
    "            #A /= A.max(1, keepdim=True)[0]\n",
    "            inp_tensor = A\n",
    "            outputs = ae(inp_tensor.to(device))\n",
    "            loss = criterion(outputs, inp_tensor.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"EPOCH:\",epoch,\"LOSS:\",loss.item())\n",
    "            ep_list.append(epoch)\n",
    "            loss_list.append(loss.item())\n",
    "            del inp_tensor,outputs,A\n",
    "            inp_tensor = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE_loss = [ep_list,loss_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_loss_1 = [ep_list,loss_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"MSE1.pkl\",'wb')\n",
    "pickle.dump(MSE_loss_1,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(0,1)\n",
    "plt.plot(ep_list,loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = state.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_img = in_data.reshape((3,320,320)).reshape((320,320,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out =ae(state.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oupp = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_img = oupp.reshape((3,320,320)).reshape((320,320,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(o_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward_list = []\n",
    "epoch_list = []\n",
    "step_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "mobilenet = models.mobilenet_v2(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data  =in_data/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    in_data = torch.FloatTensor(in_data).to(device)\n",
    "    in_data = mobilenet.features(in_data)\n",
    "    in_data = nn.AvgPool2d(7,7)(in_data)\n",
    "    in_data = nn.Flatten()(in_data)\n",
    "    in_data = in_data.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = np.concatenate((in_data[0],inps)).reshape(1,1283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    st = torch.FloatTensor(ap).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st[:,-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = in_data.reshape(128,100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PID_Controller(cmd,e_v,steer):\n",
    "    speed_limit = 60\n",
    "    min_speed = 10\n",
    "    v = e_v.get_velocity()\n",
    "    kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "    if kmh > speed_limit:\n",
    "        throttle = 0.1 + + random.random()/8\n",
    "        brake = 0.9\n",
    "    elif kmh < min_speed:\n",
    "        throttle = 0.4 + random.random()/8\n",
    "        brake = 0.0\n",
    "    else:\n",
    "        throttle = 0.1 + random.random()/8\n",
    "        brake = 0\n",
    "    \n",
    "    if (val == 0  or val ==1):\n",
    "        #Go Straight\n",
    "        \n",
    "        if abs(steer)> 0.1:\n",
    "            \n",
    "            throttle = 0.1 +  random.random()/8\n",
    "            \n",
    "                \n",
    "            brake = (kmh-10)/50\n",
    "            \n",
    "        else:\n",
    "            throttle = (60-kmh)/50 + random.random()/8\n",
    "            brake = 0\n",
    "            \n",
    "        \n",
    "        #s_clip_n = -0.15\n",
    "        #s_clip_p = 0.15\n",
    "        #t_clip_n = 0.4\n",
    "        #t_clip_p = 1.0\n",
    "\n",
    "    if (val == 2 or val == 5):\n",
    "        # Go right\n",
    "        \n",
    "        if steer < 0:\n",
    "            brake = (kmh-10)/50\n",
    "            throttle = 0.1\n",
    "        if steer > 0:\n",
    "            throttle = (60-kmh)/50 + random.random()/8\n",
    "            brake = 0\n",
    "        #s_clip_n = 0.25\n",
    "        #s_clip_p = 0.6\n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.4\n",
    "\n",
    "    if (val == 3 or val == 4):\n",
    "        # Go Left\n",
    "        if steer < 0 :\n",
    "            throttle = (60-kmh)/50 + random.random()/8\n",
    "            brake = 0\n",
    "        if steer > 0 :\n",
    "            brake = (kmh-10)/50\n",
    "            throttle = 0.1\n",
    "        #s_clip_n = -0.6\n",
    "        #s_clip_p = -0.25\n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.4\n",
    "    if throttle <= 0:\n",
    "        throttle = 0.05 + random.random()/50\n",
    "    if throttle >= 0.4:\n",
    "        throttle = 0.4 + random.random()/8\n",
    "    if brake < 0:\n",
    "        brake = 0\n",
    "    if brake >= 1:\n",
    "        brake = 0.9\n",
    "    return throttle,brake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def way_cal(ego_vehicle,val,scenario = None):\n",
    "    way = ego_vehicle.get_transform()\n",
    "    #speed = scenario._veh.speed\n",
    "    if scenario != None:\n",
    "        way = scenario._target_lane_waypoint.transform\n",
    "        way.location.x = scenario._veh.transform.as_carla_transform().location.x\n",
    "    if (val == 0  or val ==1):\n",
    "        way.location.x += 100       \n",
    "    if (val == 2 or val == 5):\n",
    "        way.location.x += 100\n",
    "        #way.location.y += 5\n",
    "    if (val == 3 or val == 4):\n",
    "        way.location.x += 100\n",
    "        #way.location.y -= 5\n",
    "    if ego_vehicle.get_transform().rotation.yaw < -35:\n",
    "        speed = 10\n",
    "        way.location.y += 10\n",
    "    if ego_vehicle.get_transform().rotation.yaw > 35:\n",
    "        speed = 10\n",
    "        way.location.y -= 10\n",
    "    return way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_safety(way):\n",
    "    d = scenario._ngsim_vehicles_in_carla._vehicle_by_vehicle_id\n",
    "    y_left = way.location.y - 3.5\n",
    "    y_right = way.location.y + 3.5\n",
    "    x_lower = ego_vehicle.get_location().x + 5\n",
    "    x_upper = ego_vehicle.get_location().x + 25\n",
    "    \n",
    "    car_in_zone = False\n",
    "    for i in d:\n",
    "        if d[i].get_location().x > x_lower and d[i].get_location().x < x_upper and d[i].get_location().y > y_left and d[i].get_location().y < y_right:\n",
    "            car_in_zone = True\n",
    "    #print(car_in_zone)\n",
    "    safe = not car_in_zone\n",
    "    #print(safe,\"LOL\")\n",
    "    return safe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform.location.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.arange(10).reshape(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.arange(4).reshape(4).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = prepare_ngsim_scenario(client)\n",
    "world = client.get_world()\n",
    "ego_vehicle = prepare_ego_vehicle(world)\n",
    "scenario.reset(ego_vehicle)\n",
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.reset(ego_vehicle)\n",
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(world.get_actors()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(steer,-1.0,1.0),brake=brake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    done = False\n",
    "    \n",
    "    scenario.reset(ego_vehicle)\n",
    "    world.tick()\n",
    "    #world = client.get_world()\n",
    "    #spectator = world.get_spectator()\n",
    "    #ego_vehicle = prepare_ego_vehicle(world)\n",
    "    #scenario.reset(ego_vehicle)\n",
    "    #world.tick()\n",
    "    while not done:\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(steer,-1.0,1.0),brake=brake))\n",
    "        r = scenario.step(ego_vehicle)\n",
    "        print(r)\n",
    "        done = r.done\n",
    "        world.tick()\n",
    "    print(\"RESET\")\n",
    "    for i in range(5):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(throttle,steer,brake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(world.get_actors()):\n",
    "    if type(i) != carla.libcarla.Vehicle:\n",
    "        print(i)\n",
    "type(list(world.get_actors())[2]) == carla.libcarla.Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = os.environ.get(\"epseed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s:\n",
    "    print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lane = scenario._lane_change.lane_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-61-59d8328a52b9>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-59d8328a52b9>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    if vehicle_laneID[i][0] == target_lane:\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def find_all():\n",
    "    target_lane = scenario._lane_change.lane_to\n",
    "    count = 0 \n",
    "    for i in l:\n",
    "        df = i._df\n",
    "        df = df[df[\"Frame ID\"] == scenario._lane_change.frame_start]\n",
    "        lane_id = df[\"Lane Identification\"].iloc[0]\n",
    "        vehicle_laneID[i.id] = [lane_id,count]\n",
    "        count+=1\n",
    "    vehicles_in_lane = []\n",
    "    vehicle_index = []\n",
    "    for i in vehicle_laneID:\n",
    "    if vehicle_laneID[i][0] == target_lane:\n",
    "        vehicles_in_lane.append(i)\n",
    "        vehicle_index.append(vehicle_laneID[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_idx():\n",
    "    d = scenario._ngsim_vehicles_in_carla._vehicle_by_vehicle_id\n",
    "    not_ego = list(d.keys())\n",
    "    ks  = scenario._ngsim_recording.env_cars\n",
    "    for i in range(len(ks)):\n",
    "        if ks[i].id not in not_ego:\n",
    "            return i\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way.location.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its a win\n",
      "1.7 0 10 Section: 0 V_Buffer: 1\n",
      "-0.5 1 54 Section: 0 V_Buffer: 1\n",
      "carla_real_traffic_scenarios.ngsim.ngsim_recording.NGSimCar.66 has undefined direction, assuming horizontal\n",
      "Its a win\n",
      "1.1 2 22 Section: 0 V_Buffer: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 3 1 Section: 0 V_Buffer: 2\n",
      "Its a win\n",
      "1.1 4 40 Section: 0 V_Buffer: 3\n",
      "Its a win\n",
      "0.8 5 38 Section: 0 V_Buffer: 4\n",
      "Its a win\n",
      "1.6 6 83 Section: 0 V_Buffer: 5\n",
      "Its a win\n",
      "1.5 7 51 Section: 0 V_Buffer: 6\n",
      "Its a win\n",
      "1.2 8 41 Section: 0 V_Buffer: 7\n",
      "Its a win\n",
      "1.1 9 50 Section: 0 V_Buffer: 8\n",
      "Its a win\n",
      "1.6 10 66 Section: 0 V_Buffer: 9\n",
      "Its a win\n",
      "1.3 11 53 Section: 0 V_Buffer: 10\n",
      "Its a win\n",
      "1.3 12 36 Section: 0 V_Buffer: 11\n",
      "Its a win\n",
      "1.0 13 46 Section: 0 V_Buffer: 12\n",
      "Its a win\n",
      "1.6 14 73 Section: 0 V_Buffer: 13\n",
      "Its a win\n",
      "1.1 15 10 Section: 0 V_Buffer: 14\n",
      "Its a win\n",
      "1.5 16 67 Section: 0 V_Buffer: 15\n",
      "Its a win\n",
      "1.4 17 57 Section: 0 V_Buffer: 16\n",
      "Its a win\n",
      "1.1 18 25 Section: 0 V_Buffer: 17\n",
      "Its a win\n",
      "1.1 19 45 Section: 0 V_Buffer: 18\n",
      "-0.07385468482971191 34.2340672537489\n",
      "Update with batches: 350\n",
      "torch.Size([350, 5, 50, 150]) torch.Size([350, 2]) torch.Size([350, 2])\n",
      "-1.0 20 10 Section: 0 V_Buffer: 18\n",
      "Its a win\n",
      "1.5 21 59 Section: 0 V_Buffer: 19\n",
      "Its a win\n",
      "1.6 22 61 Section: 0 V_Buffer: 20\n",
      "Its a win\n",
      "1.5 23 46 Section: 0 V_Buffer: 21\n",
      "Its a win\n",
      "1.6 24 46 Section: 1 V_Buffer: 1\n",
      "Its a win\n",
      "1.5 25 50 Section: 1 V_Buffer: 2\n",
      "-0.7 26 59 Section: 1 V_Buffer: 2\n",
      "Its a win\n",
      "1.5 27 93 Section: 1 V_Buffer: 3\n",
      "Its a win\n",
      "1.6 28 55 Section: 1 V_Buffer: 4\n",
      "-0.9 29 56 Section: 1 V_Buffer: 4\n",
      "Its a win\n",
      "1.5 30 32 Section: 1 V_Buffer: 5\n",
      "-1.1 31 25 Section: 1 V_Buffer: 5\n",
      "Its a win\n",
      "1.5 32 77 Section: 1 V_Buffer: 6\n",
      "Its a win\n",
      "1.6 33 85 Section: 1 V_Buffer: 7\n",
      "Its a win\n",
      "1.8 34 78 Section: 1 V_Buffer: 8\n",
      "Its a win\n",
      "1.7 35 64 Section: 1 V_Buffer: 9\n",
      "Its a win\n",
      "1.5 36 69 Section: 1 V_Buffer: 10\n",
      "Its a win\n",
      "1.8 37 60 Section: 1 V_Buffer: 11\n",
      "-0.4 38 58 Section: 1 V_Buffer: 11\n",
      "Its a win\n",
      "1.5 39 45 Section: 1 V_Buffer: 12\n",
      "-0.10534843057394028 29.16750867485083\n",
      "Update with batches: 553\n",
      "torch.Size([553, 5, 50, 150]) torch.Size([553, 2]) torch.Size([553, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 40 3 Section: 1 V_Buffer: 12\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Its a win\n",
      "1.9 41 47 Section: 1 V_Buffer: 13\n",
      "Its a win\n",
      "1.5 42 64 Section: 1 V_Buffer: 14\n",
      "-0.8 43 42 Section: 1 V_Buffer: 14\n",
      "Its a win\n",
      "1.5 44 62 Section: 1 V_Buffer: 15\n",
      "-0.4 45 54 Section: 1 V_Buffer: 15\n",
      "-0.7 46 45 Section: 1 V_Buffer: 15\n",
      "-1.0 47 16 Section: 1 V_Buffer: 15\n",
      "Its a win\n",
      "1.5 48 52 Section: 1 V_Buffer: 16\n",
      "Close to win\n",
      "Close to win\n",
      "-0.09999999999999998 49 44 Section: 1 V_Buffer: 16\n",
      "Its a win\n",
      "1.6 50 78 Section: 1 V_Buffer: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 51 3 Section: 1 V_Buffer: 17\n",
      "-1.0 52 26 Section: 1 V_Buffer: 17\n",
      "-0.7 53 51 Section: 1 V_Buffer: 17\n",
      "Its a win\n",
      "1.5 54 54 Section: 1 V_Buffer: 18\n",
      "-1.0 55 13 Section: 1 V_Buffer: 18\n",
      "Its a win\n",
      "1.6 56 54 Section: 1 V_Buffer: 19\n",
      "Close to win\n",
      "-0.4 57 53 Section: 1 V_Buffer: 19\n",
      "Its a win\n",
      "1.7 58 61 Section: 1 V_Buffer: 20\n",
      "-0.7 59 42 Section: 1 V_Buffer: 20\n",
      "Its a win\n",
      "0.04973764717578888 -7.861942648887634\n",
      "Update with batches: 357\n",
      "torch.Size([357, 5, 50, 150]) torch.Size([357, 2]) torch.Size([357, 2])\n",
      "1.8 60 34 Section: 1 V_Buffer: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 61 1 Section: 2 V_Buffer: 0\n",
      "Close to win\n",
      "-0.4 62 44 Section: 2 V_Buffer: 0\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "-0.30000000000000004 63 71 Section: 2 V_Buffer: 0\n",
      "-1.1 64 22 Section: 2 V_Buffer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 65 1 Section: 2 V_Buffer: 0\n",
      "-1.0 66 11 Section: 2 V_Buffer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 67 3 Section: 2 V_Buffer: 0\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Its a win\n",
      "1.9 68 53 Section: 2 V_Buffer: 1\n",
      "Its a win\n",
      "1.5 69 43 Section: 2 V_Buffer: 2\n",
      "Close to win\n",
      "-0.5 70 46 Section: 2 V_Buffer: 2\n",
      "Its a win\n",
      "1.5 71 38 Section: 2 V_Buffer: 3\n",
      "Close to win\n",
      "-0.4 72 46 Section: 2 V_Buffer: 3\n",
      "Its a win\n",
      "1.5 73 63 Section: 2 V_Buffer: 4\n",
      "Its a win\n",
      "1.7 74 63 Section: 2 V_Buffer: 5\n",
      "Its a win\n",
      "1.6 75 38 Section: 2 V_Buffer: 6\n",
      "-0.6 76 44 Section: 2 V_Buffer: 6\n",
      "Its a win\n",
      "1.6 77 75 Section: 2 V_Buffer: 7\n",
      "Its a win\n",
      "1.6 78 50 Section: 2 V_Buffer: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switch synchronous_mode=True\n",
      "Change fixed_delta_seconds=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 79 1 Section: 2 V_Buffer: 8\n",
      "0.07414429634809494 72.40335315465927\n",
      "Update with batches: 293\n",
      "torch.Size([293, 5, 50, 150]) torch.Size([293, 2]) torch.Size([293, 2])\n",
      "-1.0 80 39 Section: 2 V_Buffer: 8\n",
      "Its a win\n",
      "1.5 81 50 Section: 2 V_Buffer: 9\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Its a win\n",
      "1.6 82 49 Section: 2 V_Buffer: 10\n",
      "Its a win\n",
      "1.8 83 55 Section: 2 V_Buffer: 11\n",
      "Its a win\n",
      "1.8 84 72 Section: 2 V_Buffer: 12\n",
      "Its a win\n",
      "1.5 85 65 Section: 2 V_Buffer: 13\n",
      "Close to win\n",
      "-0.30000000000000004 86 45 Section: 2 V_Buffer: 13\n",
      "Its a win\n",
      "1.6 87 60 Section: 2 V_Buffer: 14\n",
      "Close to win\n",
      "Close to win\n",
      "-0.5 88 56 Section: 2 V_Buffer: 14\n",
      "Its a win\n",
      "1.8 89 15 Section: 2 V_Buffer: 15\n",
      "Its a win\n",
      "1.6 90 73 Section: 2 V_Buffer: 16\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Its a win\n",
      "1.9 91 53 Section: 2 V_Buffer: 17\n",
      "Close to win\n",
      "-0.4 92 44 Section: 2 V_Buffer: 17\n",
      "Its a win\n",
      "1.8 93 70 Section: 2 V_Buffer: 18\n",
      "Close to win\n",
      "Close to win\n",
      "Close to win\n",
      "Its a win\n",
      "1.9 94 61 Section: 2 V_Buffer: 19\n"
     ]
    }
   ],
   "source": [
    "epochs = 211\n",
    "freq = 5\n",
    "freq_n = 3\n",
    "update_freq = 20\n",
    "decay_freq = 1000\n",
    "decay_c = 1000\n",
    "#val = 0\n",
    "min_r_avg = -1\n",
    "steer_w = 1\n",
    "min_steer_w = 0\n",
    "steer_decay = 0.1\n",
    "mn=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "last_epoch = -1\n",
    "\n",
    "victory = 0\n",
    "victory_buffer = 0\n",
    "for epoch in range(0,epochs):\n",
    "    step = 0\n",
    "    \n",
    "    #scenario = prepare_ngsim_scenario(client)\n",
    "    #world = client.get_world()\n",
    "    #ego_vehicle = prepare_ego_vehicle(world)\n",
    "    #scenario.reset(ego_vehicle)\n",
    "    #c = world.tick()\n",
    "    #print(len(list(world.get_actors())))\n",
    "    #del ego_vehicle\n",
    "    ids = list(world.get_actors())[0]\n",
    "    carla.command.DestroyActor(ids)\n",
    "    '''\n",
    "    for i in list(world.get_actors()):\n",
    "        if type(i) != carla.libcarla.Vehicle:\n",
    "            ids = i.id\n",
    "            carla.command.DestroyActor(ids)\n",
    "    '''\n",
    "    world = client.get_world()\n",
    "    #spectator = world.get_spectator()\n",
    "    ego_vehicle = prepare_ego_vehicle(world)\n",
    "    \n",
    "    #scenario.close()\n",
    "    #scenario = prepare_ngsim_scenario(client)\n",
    "    \n",
    "    #time.sleep(3)\n",
    "    #world = client.get_world()\n",
    "    #spectator = world.get_spectator()\n",
    "    #client.reload_world()\n",
    "    \n",
    "    #ego_vehicle = prepare_ego_vehicle(world)\n",
    "    \n",
    "    scenario.reset(ego_vehicle)\n",
    "    c = world.tick()\n",
    "    \n",
    "    ego_vehicle.apply_control(carla.VehicleControl(manual_gear_shift=True, gear=4))\n",
    "    #ego_vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=1.0))\n",
    "    c = world.tick()\n",
    "    #ego_vehicle.apply_control(carla.VehicleControl(manual_gear_shift=False))\n",
    "    #time.sleep(4)\n",
    "    #ego_vehicle.apply_control(carla.VehicleControl(brake=0.0))\n",
    "    c = world.tick()\n",
    "    \n",
    "    #way = scenario._target_lane_waypoint.transform\n",
    "    speed = scenario._veh.speed\n",
    "    #c = world.tick()\n",
    "    done = False\n",
    "    total_r = 0\n",
    "    val = 0\n",
    "    way = scenario._target_lane_waypoint.transform\n",
    "    target_boundary = scenario._target_lane_waypoint.transform\n",
    "    ##left_y = target_boundary.location.y - 5\n",
    "    #right_y = target_boundary.location.y + 5\n",
    "    #initial_x \n",
    "    #way = way_cal(ego_vehicle,val)\n",
    "    #print(scenario._sampled_dataset_excerpt_info)\n",
    "    t_clip_n = 0.0\n",
    "    t_clip_p = 1.0\n",
    "    \n",
    "    s_clip_n = -1.0\n",
    "    s_clip_p = 1.0\n",
    "    cmd_buffer = [0]\n",
    "    yaw_buffer = [0]\n",
    "    \n",
    "    steer = 0\n",
    "    steer_aug = 0.1\n",
    "    prep_limit = 10*3\n",
    "    pid = VehiclePIDController(ego_vehicle,0.7)\n",
    "    lock = 0\n",
    "    if victory_buffer > 20:\n",
    "        section+=1\n",
    "        victory_buffer = 0\n",
    "    while not done:\n",
    "        '''\n",
    "        while True:\n",
    "            #print(current_frame,c)\n",
    "            if current_frame >= c:\n",
    "                #print(current_frame,c)\n",
    "                break\n",
    "        '''\n",
    "        speed = scenario._veh.speed/1.603\n",
    "        way = scenario._target_lane_waypoint.transform\n",
    "        way.location.x = ego_vehicle.get_location().x + 30\n",
    "        safe = check_safety(way)\n",
    "        #print(safe)\n",
    "        if step < prep_limit:\n",
    "            k = pid.run_step(speed,way)\n",
    "            #print(k.throttle)\n",
    "            ego_vehicle.apply_control(carla.VehicleControl(throttle=k.throttle, steer=np.clip(0.0,-1.0,1.0),brake=k.brake))\n",
    "        else:\n",
    "            if lock == 0:\n",
    "                pid = VehiclePIDController(ego_vehicle,0.7)\n",
    "                lock = 1\n",
    "            birdview = birdview_producer.produce(\n",
    "                agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "                )\n",
    "            a = birdview[0].reshape(1,50,150)\n",
    "            a = np.append(a,birdview[1].reshape(1,50,150),axis=0)\n",
    "            a = np.append(a,birdview[2].reshape(1,50,150),axis=0)\n",
    "            a = np.append(a,birdview[3].reshape(1,50,150),axis=0)\n",
    "            a = np.append(a,birdview[4].reshape(1,50,150),axis=0)\n",
    "            #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "            #rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "            in_data = a.reshape(1,5,50,150)\n",
    "            '''\n",
    "            for i in range(3):\n",
    "                rgb[:,:,i] = (rgb[:,:,i] - mn[i])/std[i]\n",
    "            '''\n",
    "            #in_data = rgb.reshape(1,3,224,224)\n",
    "            '''\n",
    "            with torch.no_grad():\n",
    "                in_data = torch.FloatTensor(in_data).to(device)\n",
    "                in_data = mobilenet.features(in_data)\n",
    "                in_data = nn.AvgPool2d(7,7)(in_data)\n",
    "                in_data = nn.Flatten()(in_data)\n",
    "                in_data = in_data.detach().cpu().numpy()\n",
    "            '''\n",
    "            \n",
    "            #in_data = mdl(in_data).numpy()\n",
    "            #in_data = in_data.reshape(in_data.shape[0],62720)\n",
    "            #in_data = in_data.reshape((1,5,186,150))\n",
    "            #in_data = input_data.reshape((1,3,320,320))\n",
    "            #print(in_data.shape)\n",
    "            if val == 0 or val == 1:\n",
    "                inps= [0,1,0]\n",
    "            if val == 2 or val == 5:\n",
    "                inps = [0,0,1]\n",
    "            if val == 4 or val ==3:\n",
    "                inps = [1,0,0]\n",
    "            #inps = np.array(inps)\n",
    "            inputs = [in_data,np.array(inps).reshape(1,3)]\n",
    "            #ap = np.concatenate((in_data[0],inps)).reshape(1,1283)\n",
    "\n",
    "            action = p.select_action(inputs)\n",
    "            #print(action)\n",
    "            #print(action)\n",
    "            #action[0] = action[0]*2 - 1\n",
    "            #action[1] = action[1]*120\n",
    "            '''\n",
    "            if (val == 0  or val ==1):\n",
    "                s_clip_n = -0.15\n",
    "                s_clip_p = 0.15\n",
    "                t_clip_n = 0.4\n",
    "                t_clip_p = 1.0\n",
    "\n",
    "            if (val == 2 or val == 5):\n",
    "                s_clip_n = 0.25\n",
    "                s_clip_p = 0.8\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "\n",
    "            if (val == 3 or val == 4):\n",
    "                s_clip_n = -0.8\n",
    "                s_clip_p = -0.25\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "            '''\n",
    "\n",
    "\n",
    "            #t_clip_n = 0.0\n",
    "            #t_clip_p = 0.7\n",
    "\n",
    "            #s_clip_n = -0.6\n",
    "            #s_clip_p = 0.6  \n",
    "            #d_action = action_space[action]\n",
    "            #steer_s = action[0]*0.1\n",
    "            #steer += steer_s\n",
    "            '''\n",
    "            if action[0]<0:\n",
    "                steer -= steer_aug\n",
    "            elif action[0]>0:\n",
    "                steer += steer_aug\n",
    "            \n",
    "            if steer < -0.1:\n",
    "                steer = -0.1\n",
    "            if steer > 0.1:\n",
    "                steer = 0.1\n",
    "            '''\n",
    "            #speed = action[0]*80+20\n",
    "            #speed = action[1]\n",
    "            #speed = math.sqrt(speed**2)\n",
    "            #_speed = np.clip(action[0], -1,1)\n",
    "            #speed = ((_speed + 1)/2)*50 + 10\n",
    "            brake = 0\n",
    "            throttle = 0\n",
    "            steer = 0\n",
    "            x = (action[0] + 1)/2\n",
    "            x = x*120\n",
    "            y = (action[1] + 1)/2\n",
    "            y = y*130\n",
    "            way.location.x =  ego_vehicle.get_location().x + x\n",
    "            #way.location.y = ego_vehicle.get_location().y + y\n",
    "            speed = y\n",
    "            '''\n",
    "            brake = 0\n",
    "            throttle = 0\n",
    "            if action[0] <0:\n",
    "                brake = action[0]\n",
    "                throttle = 0\n",
    "            else:\n",
    "                throttle = action[0]\n",
    "                brake = 0\n",
    "            '''\n",
    "            '''\n",
    "            if epoch > 400:\n",
    "                if (val == 0  or val ==1):\n",
    "                    s_clip_n = -0.15\n",
    "                    s_clip_p = 0.15\n",
    "                    t_clip_n = 0.4\n",
    "                    t_clip_p = 1.0\n",
    "\n",
    "                if (val == 2 or val == 5):\n",
    "                    s_clip_n = 0.25\n",
    "                    s_clip_p = 0.6\n",
    "                    t_clip_n = 0.0\n",
    "                    t_clip_p = 0.4\n",
    "\n",
    "                if (val == 3 or val == 4):\n",
    "                    s_clip_n = -0.6\n",
    "                    s_clip_p = -0.25\n",
    "                    t_clip_n = 0.0\n",
    "                    t_clip_p = 0.4\n",
    "            '''\n",
    "            #if epoch < 20:\n",
    "            #print(throttle,steer,brake)\n",
    "            #pid = VehiclePIDController(ego_vehicle)\n",
    "\n",
    "            k = pid.run_step(speed,way)\n",
    "            #throttle = k.throttle\n",
    "            #brake = k.brake\n",
    "\n",
    "            avg_steer = k.steer \n",
    "            brake = k.brake\n",
    "            throttle = k.throttle\n",
    "            #print(\"SteerDiff:\",abs(steer-k.steer),k.steer,steer)\n",
    "            #print(throttle,steer,brake)\n",
    "            #avg_steer= k.steer\n",
    "            ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(avg_steer,-1.0,1.0),brake=brake))\n",
    "\n",
    "        #ego_vehicle.apply_control(carla.VehicleControl(throttle=np.clip(throttle, t_clip_n, t_clip_p), steer=np.clip(action[1], s_clip_n, s_clip_p)))#,brake=np.clip(brake, 0.0, 1.0)))\n",
    "        \n",
    "        \n",
    "        #print(steer,speed)\n",
    "        try:\n",
    "            cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"ERROR\")\n",
    "            reward = -1\n",
    "            done = True\n",
    "        #reward = reward/2\n",
    "        \n",
    "        '''\n",
    "        if reward < 0 :\n",
    "            reward = -0.1\n",
    "        '''\n",
    "        \n",
    "        val = cmd.value\n",
    "        #way = way_cal(ego_vehicle,val)\n",
    "        cmd_buffer.append(val)\n",
    "        yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "        if section == 0:\n",
    "            if len(cmd_buffer) > 10:\n",
    "                if _['on_target_lane']:\n",
    "                    reward = 1 \n",
    "                    done = True\n",
    "        if section == 1:\n",
    "            if len(cmd_buffer) > 10:\n",
    "                if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and total_r>=0.5:\n",
    "                    reward = 1 \n",
    "                    done = True\n",
    "        if section == 2:\n",
    "            if len(cmd_buffer) > 10:\n",
    "                if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and sum([abs(x) for x in yaw_buffer[-10:]])/10<=10 and total_r>=0.5:\n",
    "                    reward = 1 \n",
    "                    done = True\n",
    "        if section==3:\n",
    "            if len(cmd_buffer) > 10:\n",
    "                if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and sum([abs(x) for x in yaw_buffer[-10:]])/10<=10 and total_r>=0.6:\n",
    "                    reward = 1 \n",
    "                    done = True\n",
    "        if section>=4:\n",
    "            if len(cmd_buffer) > 10:\n",
    "                if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and sum([abs(x) for x in yaw_buffer[-10:]])/10<=5 and total_r>=0.8:\n",
    "                    reward = 1 \n",
    "                    done = True\n",
    "        \n",
    "        if total_r >=0.9:\n",
    "            print(\"Close to win\")\n",
    "        if reward >= 1:\n",
    "            victory_buffer+=1\n",
    "            print(\"Its a win\")\n",
    "            \n",
    "        \n",
    "            #p.save(\"WinModel\"+str(epoch)+\".mdl\")\n",
    "        #way = _[\"scenario_data\"][\"original_veh_transform\"]\n",
    "        #way = scenario._target_lane_waypoint.transform  \n",
    "        \n",
    "        \n",
    "        #print(action[0],action[1])\n",
    "        #print(done)\n",
    "        #if done:\n",
    "        #    print(_)\n",
    "        #print(_)\n",
    "        '''\n",
    "        if (val == 0  or val ==1):\n",
    "            if action[0] > 0.0:\n",
    "                reward += 0.01\n",
    "            if action[1] < 0.1 and action[1]> -0.1:\n",
    "                reward += 0.01\n",
    "                \n",
    "\n",
    "        if (val == 2 or val == 5):\n",
    "            if action[0] <0.1:\n",
    "                reward += 0.01\n",
    "            if action[1] > 0.0:\n",
    "                reward += 0.01\n",
    "\n",
    "        if (val == 3 or val == 4):\n",
    "            if action[0] < 0.1:\n",
    "                reward += 0.01\n",
    "            if action[1] < 0.0:\n",
    "                reward += 0.01\n",
    "        '''\n",
    "        #reward += step\n",
    "        '''\n",
    "        v = ego_vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "        \n",
    "        if kmh < 60 & kmh > 0.2:\n",
    "            #done = False\n",
    "            reward += 1 #-1\n",
    "            # Reward lighter steering when moving\n",
    "            if np.abs(action[1]) < 0.3:\n",
    "                reward += 1\n",
    "            elif np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "                reward -= 0.1\n",
    "            elif np.abs(action[1]) >= 0.9:\n",
    "                reward -= 0.2\n",
    "        elif kmh < 0.2:\n",
    "            reward -= 0.1\n",
    "        else:\n",
    "            #print(\"Maybe never\")\n",
    "            reward += 0.01\n",
    "            if np.abs(action[1]) < 0.3:\n",
    "                reward += 0.12\n",
    "            # Reduce score for heavy steering\n",
    "            if np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "                reward -= 0.17\n",
    "            elif np.abs(action[1]) >= 0.9:\n",
    "                reward -= 0.21\n",
    "        '''\n",
    "        '''\n",
    "        rgb = BirdViewProducer.as_rgb(birdview)\n",
    "        cv2.imshow('Frame',rgb)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        '''\n",
    "        if step < prep_limit:\n",
    "            pass\n",
    "        else:\n",
    "            #print(\"HI\")\n",
    "            p.buffer.rewards.append(reward)\n",
    "            p.buffer.is_terminals.append(done)\n",
    "        \n",
    "        total_r += reward\n",
    "        step += 1\n",
    "        \n",
    "        '''\n",
    "        if step % freq ==0 :\n",
    "            print(step)\n",
    "            p.update()\n",
    "        \n",
    "        if step % freq_n == 0:\n",
    "            p.decay_action_std(0.05,0.1)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        world.tick()\n",
    "    #total_r += step/10\n",
    "    '''\n",
    "    if epoch > 50:\n",
    "        \n",
    "        if sum(total_reward_list[-50:])/len(total_reward_list[-50:]) > min_r_avg or sum(step_list) > decay_freq:\n",
    "            decay_freq += decay_c\n",
    "            #decay_c -= 50\n",
    "            #print(\"Decaying:\",p.action_std)\n",
    "            p.decay_action_std(0.01,0.1)\n",
    "            \n",
    "            min_r_avg = sum(total_reward_list[-50:])/len(total_reward_list[-50:])\n",
    "    '''\n",
    "    if epoch%update_freq ==0 and epoch != 0 and len(p.buffer.states)>1:\n",
    "            print(k.steer,speed)\n",
    "            print(\"Update with batches:\",len(p.buffer.states))\n",
    "            p.update()\n",
    "            #update_freq = 10\n",
    "            if steer_w > min_steer_w +0.1:\n",
    "                steer_w -= steer_decay\n",
    "    '''\n",
    "    else:\n",
    "            print(total_r,epoch,step)\n",
    "            total_reward_list.append(total_r)\n",
    "            epoch_list.append(epoch)\n",
    "            step_list.append(step)\n",
    "            continue\n",
    "    #except Exception as e:\n",
    "        #print(\"Error:\",e)\n",
    "        #pass\n",
    "    '''\n",
    "    if step <10 and epoch != 0 and epoch!=last_epoch+1:\n",
    "        last_epoch = epoch\n",
    "        scenario = prepare_ngsim_scenario(client)\n",
    "        world = client.get_world()\n",
    "        ego_vehicle = prepare_ego_vehicle(world)\n",
    "        scenario.reset(ego_vehicle)\n",
    "        world.tick()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(total_r,epoch,step,\"Section:\",section,\"V_Buffer:\",victory_buffer)\n",
    "    total_reward_list.append(total_r)\n",
    "    epoch_list.append(epoch)\n",
    "    step_list.append(step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.buffer.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(\"Latest.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.load(\"Latest.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "tr_x = []\n",
    "tr_y = []\n",
    "e_x = []\n",
    "e_y = []\n",
    "spd = []\n",
    "spd2 = []\n",
    "#scenario = prepare_ngsim_scenario(client)\n",
    "#world = client.get_world()\n",
    "#ego_vehicle = prepare_ego_vehicle(world)\n",
    "#scenario.reset(ego_vehicle)\n",
    "#c = world.tick()\n",
    "#print(len(list(world.get_actors())))\n",
    "#del ego_vehicle\n",
    "ids = list(world.get_actors())[0]\n",
    "carla.command.DestroyActor(ids)\n",
    "'''\n",
    "for i in list(world.get_actors()):\n",
    "    if type(i) != carla.libcarla.Vehicle:\n",
    "        ids = i.id\n",
    "        carla.command.DestroyActor(ids)\n",
    "'''\n",
    "world = client.get_world()\n",
    "#spectator = world.get_spectator()\n",
    "ego_vehicle = prepare_ego_vehicle(world)\n",
    "\n",
    "#scenario.close()\n",
    "#scenario = prepare_ngsim_scenario(client)\n",
    "\n",
    "#time.sleep(3)\n",
    "#world = client.get_world()\n",
    "#spectator = world.get_spectator()\n",
    "#client.reload_world()\n",
    "\n",
    "#ego_vehicle = prepare_ego_vehicle(world)\n",
    "\n",
    "scenario.reset(ego_vehicle)\n",
    "c = world.tick()\n",
    "c = world.tick()\n",
    "ego_vehicle.apply_control(carla.VehicleControl(manual_gear_shift=True, gear=4))\n",
    "c = world.tick()\n",
    "\n",
    "#way = scenario._target_lane_waypoint.transform\n",
    "speed = scenario._veh.speed\n",
    "#c = world.tick()\n",
    "done = False\n",
    "total_r = 0\n",
    "val = 0\n",
    "way = scenario._target_lane_waypoint.transform\n",
    "#way = way_cal(ego_vehicle,val)\n",
    "#print(scenario._sampled_dataset_excerpt_info)\n",
    "t_clip_n = 0.0\n",
    "t_clip_p = 1.0\n",
    "\n",
    "s_clip_n = -1.0\n",
    "s_clip_p = 1.0\n",
    "cmd_buffer = [0]\n",
    "yaw_buffer = [0]\n",
    "steer = 0\n",
    "steer_aug = 0.1\n",
    "prep_limit = 10*1\n",
    "pid = VehiclePIDController(ego_vehicle,0.7)\n",
    "lock = 0\n",
    "while not done:\n",
    "    '''\n",
    "    while True:\n",
    "        #print(current_frame,c)\n",
    "        if current_frame >= c:\n",
    "            #print(current_frame,c)\n",
    "            break\n",
    "    '''\n",
    "    speed = scenario._veh.speed/1.603\n",
    "    way = scenario._target_lane_waypoint.transform\n",
    "    way.location.x = ego_vehicle.get_location().x + 30\n",
    "    safe = check_safety(way)\n",
    "    #print(safe)\n",
    "    #print(speed)\n",
    "    ids = check_idx()\n",
    "    actions = scenario._ngsim_recording.env_cars[ids].policy()\n",
    "    scenario._ngsim_recording.env_cars[ids].step(actions)\n",
    "    #actions = actions/0.1\n",
    "    #print(actions)\n",
    "    if step < prep_limit:\n",
    "        k = pid.run_step(speed,way)\n",
    "        #print(k.throttle)\n",
    "        \n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=k.throttle, steer=np.clip(0.0,-1.0,1.0),brake=k.brake))\n",
    "    else:\n",
    "        if lock == 0:\n",
    "            pid = VehiclePIDController(ego_vehicle,0.7)\n",
    "            lock = 1\n",
    "        birdview = birdview_producer.produce(\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )\n",
    "        a = birdview[0].reshape(1,186,150)\n",
    "        a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "        a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "        a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "        a = np.append(a,birdview[4].reshape(1,186,150),axis=0)\n",
    "        #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "        #rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "        in_data = a.reshape(1,5,186,150)\n",
    "        #a = birdview[0].reshape(1,186,150)\n",
    "        #a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "        #a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "        #a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "        #a = np.append(a,birdview[4].reshape(1,186,150),axis=0)\n",
    "        #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "        '''\n",
    "        rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "        #in_data = a.reshape(1,5,186,150)\n",
    "        for i in range(3):\n",
    "            rgb[:,:,i] = (rgb[:,:,i] - mn[i])/std[i]\n",
    "        in_data = rgb.reshape(1,3,224,224)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            in_data = torch.FloatTensor(in_data).to(device)\n",
    "            in_data = mobilenet.features(in_data)\n",
    "            in_data = nn.AvgPool2d(7,7)(in_data)\n",
    "            in_data = nn.Flatten()(in_data)\n",
    "            in_data = in_data.detach().cpu().numpy()\n",
    "        #in_data = mdl(in_data).numpy()\n",
    "        #in_data = in_data.reshape(in_data.shape[0],62720)\n",
    "        #in_data = in_data.reshape((1,5,186,150))\n",
    "        #in_data = input_data.reshape((1,3,320,320))\n",
    "        #print(in_data.shape)\n",
    "        '''\n",
    "        if val == 0 or val == 1:\n",
    "            inps= [0,1,0]\n",
    "        if val == 2 or val == 5:\n",
    "            inps = [0,0,1]\n",
    "        if val == 4 or val ==3:\n",
    "            inps = [1,0,0]\n",
    "        #inps = np.array(inps)\n",
    "        inputs = [in_data,np.array(inps).reshape(1,3)]\n",
    "        #ap = np.concatenate((in_data[0],inps)).reshape(1,1283)\n",
    "\n",
    "        action = p.select_action(inputs,True)\n",
    "        #print(action)\n",
    "        #print(action)\n",
    "        #action[0] = action[0]*2 - 1\n",
    "        #action[1] = action[1]*120\n",
    "        '''\n",
    "        if (val == 0  or val ==1):\n",
    "            s_clip_n = -0.15\n",
    "            s_clip_p = 0.15\n",
    "            t_clip_n = 0.4\n",
    "            t_clip_p = 1.0\n",
    "\n",
    "        if (val == 2 or val == 5):\n",
    "            s_clip_n = 0.25\n",
    "            s_clip_p = 0.8\n",
    "            t_clip_n = 0.0\n",
    "            t_clip_p = 0.4\n",
    "\n",
    "        if (val == 3 or val == 4):\n",
    "            s_clip_n = -0.8\n",
    "            s_clip_p = -0.25\n",
    "            t_clip_n = 0.0\n",
    "            t_clip_p = 0.4\n",
    "        '''\n",
    "\n",
    "\n",
    "        #t_clip_n = 0.0\n",
    "        #t_clip_p = 0.7\n",
    "\n",
    "        #s_clip_n = -0.6\n",
    "        #s_clip_p = 0.6  \n",
    "        #d_action = action_space[action]\n",
    "        #steer_s = action[0]*0.1\n",
    "        #steer += steer_s\n",
    "        steer = 0\n",
    "        x = (action[0] + 1)/2\n",
    "        x = x*100\n",
    "        y = (action[1] + 1)/2\n",
    "        y = y*130\n",
    "        way.location.x =  ego_vehicle.get_location().x + x\n",
    "        speed = y\n",
    "        #way.location.y = ego_vehicle.get_location().y + y\n",
    "        #way.location.x =  ego_vehicle.get_location().x + action[0]\n",
    "        #way.location.y = ego_vehicle.get_location().y + action[1]\n",
    "        '''\n",
    "        if steer < -0.1:\n",
    "            steer = -0.1\n",
    "        if steer > 0.1:\n",
    "            steer = 0.1\n",
    "        '''\n",
    "        #speed = action[0]*80+20\n",
    "        #print(speed)\n",
    "        #speed = action[1]\n",
    "        #speed = math.sqrt(speed**2)\n",
    "        #_speed = np.clip(action[0], -1,1)\n",
    "        #speed = ((_speed + 1)/2)*50 + 10\n",
    "        brake = 0\n",
    "        throttle = 0\n",
    "        '''\n",
    "        brake = 0\n",
    "        throttle = 0\n",
    "        if action[0] <0:\n",
    "            brake = action[0]\n",
    "            throttle = 0\n",
    "        else:\n",
    "            throttle = action[0]\n",
    "            brake = 0\n",
    "        '''\n",
    "        '''\n",
    "        if epoch > 400:\n",
    "            if (val == 0  or val ==1):\n",
    "                s_clip_n = -0.15\n",
    "                s_clip_p = 0.15\n",
    "                t_clip_n = 0.4\n",
    "                t_clip_p = 1.0\n",
    "\n",
    "            if (val == 2 or val == 5):\n",
    "                s_clip_n = 0.25\n",
    "                s_clip_p = 0.6\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "\n",
    "            if (val == 3 or val == 4):\n",
    "                s_clip_n = -0.6\n",
    "                s_clip_p = -0.25\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "        '''\n",
    "        #if epoch < 20:\n",
    "        #print(throttle,steer,brake)\n",
    "        #pid = VehiclePIDController(ego_vehicle)\n",
    "\n",
    "        k = pid.run_step(speed,way)\n",
    "        #throttle = k.throttle\n",
    "        #brake = k.brake\n",
    "\n",
    "        avg_steer = k.steer \n",
    "        brake = k.brake\n",
    "        throttle = k.throttle\n",
    "        #print(\"SteerDiff:\",abs(steer-k.steer),k.steer,steer)\n",
    "        #print(steer,k.steer)\n",
    "        #avg_steer = k.steer\n",
    "        '''\n",
    "        if actions[0]>0:\n",
    "            \n",
    "            throttle = actions[0]\n",
    "            brake = 0.0\n",
    "        else:\n",
    "            throttle = 0.0\n",
    "            brake = -1*actions[0]\n",
    "        '''\n",
    "        #avg_steer = k.steer\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(avg_steer,-1.0,1.0),brake=brake))\n",
    "        print(way.location.x,way.location.y,ego_vehicle.get_location().x,ego_vehicle.get_location().y)\n",
    "        tr_x.append(x)\n",
    "        tr_y.append(way.location.y)\n",
    "        e_x.append(ego_vehicle.get_location().x)\n",
    "        e_y.append(ego_vehicle.get_location().y)\n",
    "        spd.append(speed)\n",
    "        spd2.append(scenario._veh.speed/1.603)\n",
    "        #ego_vehicle.apply_control(carla.VehicleControl(throttle=np.clip(throttle, t_clip_n, t_clip_p), steer=np.clip(action[1], s_clip_n, s_clip_p)))#,brake=np.clip(brake, 0.0, 1.0)))\n",
    "\n",
    "\n",
    "    #print(steer,speed)\n",
    "    try:\n",
    "        cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"ERROR\")\n",
    "        reward = -1\n",
    "        done = True\n",
    "\n",
    "\n",
    "    '''\n",
    "    if reward < 0 :\n",
    "        reward = -0.1\n",
    "    '''\n",
    "\n",
    "    val = cmd.value\n",
    "    #way = way_cal(ego_vehicle,val)\n",
    "    cmd_buffer.append(val)\n",
    "    yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "    \n",
    "    if len(cmd_buffer) > 10:\n",
    "        if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and sum([abs(x) for x in yaw_buffer[-10:]])/10<=10 and total_r>=0.9:\n",
    "            reward = 1\n",
    "            done = True\n",
    "\n",
    "    \n",
    "    if total_r >=0.9:\n",
    "        print(\"Close to win\")\n",
    "    if reward >= 1:\n",
    "        print(\"Its a win\")\n",
    "\n",
    "\n",
    "        #p.save(\"WinModel\"+str(epoch)+\".mdl\")\n",
    "    #way = _[\"scenario_data\"][\"original_veh_transform\"]\n",
    "    #way = scenario._target_lane_waypoint.transform  \n",
    "\n",
    "\n",
    "    #print(action[0],action[1])\n",
    "    #print(done)\n",
    "    #if done:\n",
    "    #    print(_)\n",
    "    #print(_)\n",
    "    '''\n",
    "    if (val == 0  or val ==1):\n",
    "        if action[0] > 0.0:\n",
    "            reward += 0.01\n",
    "        if action[1] < 0.1 and action[1]> -0.1:\n",
    "            reward += 0.01\n",
    "\n",
    "\n",
    "    if (val == 2 or val == 5):\n",
    "        if action[0] <0.1:\n",
    "            reward += 0.01\n",
    "        if action[1] > 0.0:\n",
    "            reward += 0.01\n",
    "\n",
    "    if (val == 3 or val == 4):\n",
    "        if action[0] < 0.1:\n",
    "            reward += 0.01\n",
    "        if action[1] < 0.0:\n",
    "            reward += 0.01\n",
    "    '''\n",
    "    #reward += step\n",
    "    '''\n",
    "    v = ego_vehicle.get_velocity()\n",
    "    kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "\n",
    "    if kmh < 60 & kmh > 0.2:\n",
    "        #done = False\n",
    "        reward += 1 #-1\n",
    "        # Reward lighter steering when moving\n",
    "        if np.abs(action[1]) < 0.3:\n",
    "            reward += 1\n",
    "        elif np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "            reward -= 0.1\n",
    "        elif np.abs(action[1]) >= 0.9:\n",
    "            reward -= 0.2\n",
    "    elif kmh < 0.2:\n",
    "        reward -= 0.1\n",
    "    else:\n",
    "        #print(\"Maybe never\")\n",
    "        reward += 0.01\n",
    "        if np.abs(action[1]) < 0.3:\n",
    "            reward += 0.12\n",
    "        # Reduce score for heavy steering\n",
    "        if np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "            reward -= 0.17\n",
    "        elif np.abs(action[1]) >= 0.9:\n",
    "            reward -= 0.21\n",
    "    '''\n",
    "    \n",
    "    rgb = BirdViewProducer.as_rgb(birdview)\n",
    "    cv2.imshow('Frame',rgb)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    if step < prep_limit:\n",
    "        pass\n",
    "    else:\n",
    "        #print(\"HI\")\n",
    "        p.buffer.rewards.append(reward)\n",
    "        p.buffer.is_terminals.append(done)\n",
    "\n",
    "    total_r += reward\n",
    "    step += 1\n",
    "    v = ego_vehicle.get_velocity()\n",
    "    kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "    #print(kmh,reward)\n",
    "    '''\n",
    "    if step % freq ==0 :\n",
    "        print(step)\n",
    "        p.update()\n",
    "\n",
    "    if step % freq_n == 0:\n",
    "        p.decay_action_std(0.05,0.1)\n",
    "\n",
    "\n",
    "    '''\n",
    "    world.tick()\n",
    "#total_r += step/10\n",
    "'''\n",
    "if epoch > 50:\n",
    "\n",
    "    if sum(total_reward_list[-50:])/len(total_reward_list[-50:]) > min_r_avg or sum(step_list) > decay_freq:\n",
    "        decay_freq += decay_c\n",
    "        #decay_c -= 50\n",
    "        #print(\"Decaying:\",p.action_std)\n",
    "        p.decay_action_std(0.01,0.1)\n",
    "\n",
    "        min_r_avg = sum(total_reward_list[-50:])/len(total_reward_list[-50:])\n",
    "'''\n",
    "'''\n",
    "if epoch%update_freq ==0 and epoch != 0:\n",
    "        print(steer)\n",
    "        print(\"Update with batches:\",len(p.buffer.states))\n",
    "        p.update()\n",
    "        if steer_w > min_steer_w +0.1:\n",
    "            steer_w -= steer_decay\n",
    "'''\n",
    "'''\n",
    "else:\n",
    "        print(total_r,epoch,step)\n",
    "        total_reward_list.append(total_r)\n",
    "        epoch_list.append(epoch)\n",
    "        step_list.append(step)\n",
    "        continue\n",
    "#except Exception as e:\n",
    "    #print(\"Error:\",e)\n",
    "    #pass\n",
    "'''\n",
    "'''\n",
    "#cv2.destroyAllWindows()\n",
    "#print(total_r,epoch,step)\n",
    "#total_reward_list.append(total_r)\n",
    "#epoch_list.append(epoch)\n",
    "#step_list.append(step)\n",
    "'''\n",
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spd,spd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yaw_buffer[11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_x = yaw_buffer[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lcr_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.reset(ego_vehicle)\n",
    "c = world.tick()\n",
    "c = world.tick()\n",
    "ego_vehicle.apply_control(carla.VehicleControl(manual_gear_shift=True, gear=4))\n",
    "c = world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().x,ego_vehicle.get_location().y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x.append(ego_vehicle.get_location().x)\n",
    "tr_y.append(ego_vehicle.get_location().y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = list(range(len(tr_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_x = (np.array(tr_x) - min(tr_x))/(max(tr_x) - min(tr_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_x = (np.array(e_y) - min(e_y))/(max(e_y) - min(e_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.append(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "#plt.xlim(-10.748,-0.748)\n",
    "#plt.ylim(min(tr_x)-0.1,max(tr_x)+0.1)\n",
    "#ax.invert_xaxis()\n",
    "#plt.ylim()\n",
    "scat = ax.scatter([],[])\n",
    "\n",
    "def anim(i):\n",
    "    scat = ax.scatter(tr_y[:i+1],tr_x[:i+1])\n",
    "#ax.scatter(e_y,e_x)\n",
    "    for j, txt in enumerate(n[:i+1]):\n",
    "            ax.annotate(txt, (tr_y[:i+1][j], tr_x[:i+1][j]))\n",
    "    return scat,\n",
    "anim = FuncAnimation(fig, anim, frames=len(n), interval=1000, repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n,list(cr_x))\n",
    "plt.plot(n,list(er_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = [0]\n",
    "ew = [0]\n",
    "lcr_x = list(cr_x)\n",
    "ler_x = list(er_x)\n",
    "for i in range(1,len(lcr_x)):\n",
    "    dw.append(lcr_x[i] - lcr_x[i-1])\n",
    "    ew.append(ler_x[i] - ler_x[i-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x*0.8 for x in ew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(n,lcr_x)\n",
    "plt.plot(n,[x*100 for x in ew])\n",
    "plt.plot(n,yaw_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, txt in enumerate(n):\n",
    "        ax.annotate(txt, (y[i], x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tr_y,tr_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(p.policy.action_log_std.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_r,step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._sampled_dataset_excerpt_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._target_lane_waypoint.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario._veh.speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = 0\n",
    "for ci in range(50):\n",
    "    step = 0\n",
    "    tr_x = []\n",
    "    tr_y = []\n",
    "    e_x = []\n",
    "    e_y = []\n",
    "    spd = []\n",
    "    spd2 = []\n",
    "    #scenario = prepare_ngsim_scenario(client)\n",
    "    #world = client.get_world()\n",
    "    #ego_vehicle = prepare_ego_vehicle(world)\n",
    "    #scenario.reset(ego_vehicle)\n",
    "    #c = world.tick()\n",
    "    #print(len(list(world.get_actors())))\n",
    "    #del ego_vehicle\n",
    "    ids = list(world.get_actors())[0]\n",
    "    carla.command.DestroyActor(ids)\n",
    "    '''\n",
    "    for i in list(world.get_actors()):\n",
    "        if type(i) != carla.libcarla.Vehicle:\n",
    "            ids = i.id\n",
    "            carla.command.DestroyActor(ids)\n",
    "    '''\n",
    "    world = client.get_world()\n",
    "    #spectator = world.get_spectator()\n",
    "    ego_vehicle = prepare_ego_vehicle(world)\n",
    "\n",
    "    #scenario.close()\n",
    "    #scenario = prepare_ngsim_scenario(client)\n",
    "\n",
    "    #time.sleep(3)\n",
    "    #world = client.get_world()\n",
    "    #spectator = world.get_spectator()\n",
    "    #client.reload_world()\n",
    "\n",
    "    #ego_vehicle = prepare_ego_vehicle(world)\n",
    "\n",
    "    scenario.reset(ego_vehicle)\n",
    "    c = world.tick()\n",
    "    c = world.tick()\n",
    "    ego_vehicle.apply_control(carla.VehicleControl(manual_gear_shift=True, gear=4))\n",
    "    c = world.tick()\n",
    "\n",
    "    #way = scenario._target_lane_waypoint.transform\n",
    "    speed = scenario._veh.speed\n",
    "    #c = world.tick()\n",
    "    done = False\n",
    "    total_r = 0\n",
    "    val = 0\n",
    "    way = scenario._target_lane_waypoint.transform\n",
    "    #way = way_cal(ego_vehicle,val)\n",
    "    #print(scenario._sampled_dataset_excerpt_info)\n",
    "    t_clip_n = 0.0\n",
    "    t_clip_p = 1.0\n",
    "\n",
    "    s_clip_n = -1.0\n",
    "    s_clip_p = 1.0\n",
    "    cmd_buffer = [0]\n",
    "    yaw_buffer = [0]\n",
    "    steer = 0\n",
    "    steer_aug = 0.1\n",
    "    prep_limit = 10*1\n",
    "    pid = VehiclePIDController(ego_vehicle,0.7)\n",
    "    lock = 0\n",
    "    while not done:\n",
    "        '''\n",
    "        while True:\n",
    "            #print(current_frame,c)\n",
    "            if current_frame >= c:\n",
    "                #print(current_frame,c)\n",
    "                break\n",
    "        '''\n",
    "        speed = scenario._veh.speed/1.603\n",
    "        way = scenario._target_lane_waypoint.transform\n",
    "        way.location.x = ego_vehicle.get_location().x + 30\n",
    "        safe = check_safety(way)\n",
    "        #print(safe)\n",
    "        #print(speed)\n",
    "        ids = check_idx()\n",
    "        actions = scenario._ngsim_recording.env_cars[ids].policy()\n",
    "        scenario._ngsim_recording.env_cars[ids].step(actions)\n",
    "        #actions = actions/0.1\n",
    "        #print(actions)\n",
    "        if step < prep_limit:\n",
    "            k = pid.run_step(speed,way)\n",
    "            #print(k.throttle)\n",
    "\n",
    "            ego_vehicle.apply_control(carla.VehicleControl(throttle=k.throttle, steer=np.clip(0.0,-1.0,1.0),brake=k.brake))\n",
    "        else:\n",
    "            if lock == 0:\n",
    "                pid = VehiclePIDController(ego_vehicle,0.7)\n",
    "                lock = 1\n",
    "            birdview = birdview_producer.produce(\n",
    "                agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "                )\n",
    "            a = birdview[0].reshape(1,186,150)\n",
    "            a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "            a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "            a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "            a = np.append(a,birdview[4].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "            #rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "            in_data = a.reshape(1,5,186,150)\n",
    "            #a = birdview[0].reshape(1,186,150)\n",
    "            #a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[4].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "            '''\n",
    "            rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "            #in_data = a.reshape(1,5,186,150)\n",
    "            for i in range(3):\n",
    "                rgb[:,:,i] = (rgb[:,:,i] - mn[i])/std[i]\n",
    "            in_data = rgb.reshape(1,3,224,224)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                in_data = torch.FloatTensor(in_data).to(device)\n",
    "                in_data = mobilenet.features(in_data)\n",
    "                in_data = nn.AvgPool2d(7,7)(in_data)\n",
    "                in_data = nn.Flatten()(in_data)\n",
    "                in_data = in_data.detach().cpu().numpy()\n",
    "            #in_data = mdl(in_data).numpy()\n",
    "            #in_data = in_data.reshape(in_data.shape[0],62720)\n",
    "            #in_data = in_data.reshape((1,5,186,150))\n",
    "            #in_data = input_data.reshape((1,3,320,320))\n",
    "            #print(in_data.shape)\n",
    "            '''\n",
    "            if val == 0 or val == 1:\n",
    "                inps= [0,1,0]\n",
    "            if val == 2 or val == 5:\n",
    "                inps = [0,0,1]\n",
    "            if val == 4 or val ==3:\n",
    "                inps = [1,0,0]\n",
    "            #inps = np.array(inps)\n",
    "            inputs = [in_data,np.array(inps).reshape(1,3)]\n",
    "            #ap = np.concatenate((in_data[0],inps)).reshape(1,1283)\n",
    "\n",
    "            action = p.select_action(inputs,True)\n",
    "            #print(action)\n",
    "            #print(action)\n",
    "            #action[0] = action[0]*2 - 1\n",
    "            #action[1] = action[1]*120\n",
    "            '''\n",
    "            if (val == 0  or val ==1):\n",
    "                s_clip_n = -0.15\n",
    "                s_clip_p = 0.15\n",
    "                t_clip_n = 0.4\n",
    "                t_clip_p = 1.0\n",
    "\n",
    "            if (val == 2 or val == 5):\n",
    "                s_clip_n = 0.25\n",
    "                s_clip_p = 0.8\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "\n",
    "            if (val == 3 or val == 4):\n",
    "                s_clip_n = -0.8\n",
    "                s_clip_p = -0.25\n",
    "                t_clip_n = 0.0\n",
    "                t_clip_p = 0.4\n",
    "            '''\n",
    "\n",
    "\n",
    "            #t_clip_n = 0.0\n",
    "            #t_clip_p = 0.7\n",
    "\n",
    "            #s_clip_n = -0.6\n",
    "            #s_clip_p = 0.6  \n",
    "            #d_action = action_space[action]\n",
    "            #steer_s = action[0]*0.1\n",
    "            #steer += steer_s\n",
    "            steer = 0\n",
    "            x = (action[0] + 1)/2\n",
    "            x = x*100\n",
    "            y = (action[1] + 1)/2\n",
    "            y = y*130\n",
    "            way.location.x =  ego_vehicle.get_location().x + x\n",
    "            speed = y\n",
    "            #way.location.y = ego_vehicle.get_location().y + y\n",
    "            #way.location.x =  ego_vehicle.get_location().x + action[0]\n",
    "            #way.location.y = ego_vehicle.get_location().y + action[1]\n",
    "            '''\n",
    "            if steer < -0.1:\n",
    "                steer = -0.1\n",
    "            if steer > 0.1:\n",
    "                steer = 0.1\n",
    "            '''\n",
    "            #speed = action[0]*80+20\n",
    "            #print(speed)\n",
    "            #speed = action[1]\n",
    "            #speed = math.sqrt(speed**2)\n",
    "            #_speed = np.clip(action[0], -1,1)\n",
    "            #speed = ((_speed + 1)/2)*50 + 10\n",
    "            brake = 0\n",
    "            throttle = 0\n",
    "            '''\n",
    "            brake = 0\n",
    "            throttle = 0\n",
    "            if action[0] <0:\n",
    "                brake = action[0]\n",
    "                throttle = 0\n",
    "            else:\n",
    "                throttle = action[0]\n",
    "                brake = 0\n",
    "            '''\n",
    "            '''\n",
    "            if epoch > 400:\n",
    "                if (val == 0  or val ==1):\n",
    "                    s_clip_n = -0.15\n",
    "                    s_clip_p = 0.15\n",
    "                    t_clip_n = 0.4\n",
    "                    t_clip_p = 1.0\n",
    "\n",
    "                if (val == 2 or val == 5):\n",
    "                    s_clip_n = 0.25\n",
    "                    s_clip_p = 0.6\n",
    "                    t_clip_n = 0.0\n",
    "                    t_clip_p = 0.4\n",
    "\n",
    "                if (val == 3 or val == 4):\n",
    "                    s_clip_n = -0.6\n",
    "                    s_clip_p = -0.25\n",
    "                    t_clip_n = 0.0\n",
    "                    t_clip_p = 0.4\n",
    "            '''\n",
    "            #if epoch < 20:\n",
    "            #print(throttle,steer,brake)\n",
    "            #pid = VehiclePIDController(ego_vehicle)\n",
    "\n",
    "            k = pid.run_step(speed,way)\n",
    "            #throttle = k.throttle\n",
    "            #brake = k.brake\n",
    "\n",
    "            avg_steer = k.steer \n",
    "            brake = k.brake\n",
    "            throttle = k.throttle\n",
    "            #print(\"SteerDiff:\",abs(steer-k.steer),k.steer,steer)\n",
    "            #print(steer,k.steer)\n",
    "            #avg_steer = k.steer\n",
    "            '''\n",
    "            if actions[0]>0:\n",
    "\n",
    "                throttle = actions[0]\n",
    "                brake = 0.0\n",
    "            else:\n",
    "                throttle = 0.0\n",
    "                brake = -1*actions[0]\n",
    "            '''\n",
    "            #avg_steer = k.steer\n",
    "            ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(avg_steer,-1.0,1.0),brake=brake))\n",
    "            #print(way.location.x,way.location.y,ego_vehicle.get_location().x,ego_vehicle.get_location().y)\n",
    "            tr_x.append(x)\n",
    "            tr_y.append(way.location.y)\n",
    "            e_x.append(ego_vehicle.get_location().x)\n",
    "            e_y.append(ego_vehicle.get_location().y)\n",
    "            spd.append(speed)\n",
    "            spd2.append(scenario._veh.speed/1.603)\n",
    "            #ego_vehicle.apply_control(carla.VehicleControl(throttle=np.clip(throttle, t_clip_n, t_clip_p), steer=np.clip(action[1], s_clip_n, s_clip_p)))#,brake=np.clip(brake, 0.0, 1.0)))\n",
    "\n",
    "\n",
    "        #print(steer,speed)\n",
    "        try:\n",
    "            cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"ERROR\")\n",
    "            reward = -1\n",
    "            done = True\n",
    "\n",
    "\n",
    "        '''\n",
    "        if reward < 0 :\n",
    "            reward = -0.1\n",
    "        '''\n",
    "\n",
    "        val = cmd.value\n",
    "        #way = way_cal(ego_vehicle,val)\n",
    "        cmd_buffer.append(val)\n",
    "        yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "\n",
    "        if len(cmd_buffer) > 10:\n",
    "            if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and sum([abs(x) for x in yaw_buffer[-10:]])/10<=10 and total_r>=0.9:\n",
    "                reward = 1\n",
    "                done = True\n",
    "\n",
    "\n",
    "        if total_r >=0.9:\n",
    "            print(\"Close to win\")\n",
    "        if reward >= 1:\n",
    "            print(\"Its a win\")\n",
    "\n",
    "\n",
    "            #p.save(\"WinModel\"+str(epoch)+\".mdl\")\n",
    "        #way = _[\"scenario_data\"][\"original_veh_transform\"]\n",
    "        #way = scenario._target_lane_waypoint.transform  \n",
    "\n",
    "\n",
    "        #print(action[0],action[1])\n",
    "        #print(done)\n",
    "        #if done:\n",
    "        #    print(_)\n",
    "        #print(_)\n",
    "        '''\n",
    "        if (val == 0  or val ==1):\n",
    "            if action[0] > 0.0:\n",
    "                reward += 0.01\n",
    "            if action[1] < 0.1 and action[1]> -0.1:\n",
    "                reward += 0.01\n",
    "\n",
    "\n",
    "        if (val == 2 or val == 5):\n",
    "            if action[0] <0.1:\n",
    "                reward += 0.01\n",
    "            if action[1] > 0.0:\n",
    "                reward += 0.01\n",
    "\n",
    "        if (val == 3 or val == 4):\n",
    "            if action[0] < 0.1:\n",
    "                reward += 0.01\n",
    "            if action[1] < 0.0:\n",
    "                reward += 0.01\n",
    "        '''\n",
    "        #reward += step\n",
    "        '''\n",
    "        v = ego_vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "\n",
    "        if kmh < 60 & kmh > 0.2:\n",
    "            #done = False\n",
    "            reward += 1 #-1\n",
    "            # Reward lighter steering when moving\n",
    "            if np.abs(action[1]) < 0.3:\n",
    "                reward += 1\n",
    "            elif np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "                reward -= 0.1\n",
    "            elif np.abs(action[1]) >= 0.9:\n",
    "                reward -= 0.2\n",
    "        elif kmh < 0.2:\n",
    "            reward -= 0.1\n",
    "        else:\n",
    "            #print(\"Maybe never\")\n",
    "            reward += 0.01\n",
    "            if np.abs(action[1]) < 0.3:\n",
    "                reward += 0.12\n",
    "            # Reduce score for heavy steering\n",
    "            if np.abs(action[1]) > 0.5 and np.abs(action[1]) < 0.9:\n",
    "                reward -= 0.17\n",
    "            elif np.abs(action[1]) >= 0.9:\n",
    "                reward -= 0.21\n",
    "        '''\n",
    "        '''\n",
    "        rgb = BirdViewProducer.as_rgb(birdview)\n",
    "        cv2.imshow('Frame',rgb)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        '''\n",
    "        if step < prep_limit:\n",
    "            pass\n",
    "        else:\n",
    "            #print(\"HI\")\n",
    "            p.buffer.rewards.append(reward)\n",
    "            p.buffer.is_terminals.append(done)\n",
    "        if reward>=1:\n",
    "            val_score+=1\n",
    "        total_r += reward\n",
    "        step += 1\n",
    "        v = ego_vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "        #print(kmh,reward)\n",
    "        #print(total_r,ci)\n",
    "        '''\n",
    "        if step % freq ==0 :\n",
    "            print(step)\n",
    "            p.update()\n",
    "\n",
    "        if step % freq_n == 0:\n",
    "            p.decay_action_std(0.05,0.1)\n",
    "\n",
    "\n",
    "        '''\n",
    "        world.tick()\n",
    "    #total_r += step/10\n",
    "    print(total_r,ci)\n",
    "    '''\n",
    "    if epoch > 50:\n",
    "\n",
    "        if sum(total_reward_list[-50:])/len(total_reward_list[-50:]) > min_r_avg or sum(step_list) > decay_freq:\n",
    "            decay_freq += decay_c\n",
    "            #decay_c -= 50\n",
    "            #print(\"Decaying:\",p.action_std)\n",
    "            p.decay_action_std(0.01,0.1)\n",
    "\n",
    "            min_r_avg = sum(total_reward_list[-50:])/len(total_reward_list[-50:])\n",
    "    '''\n",
    "    '''\n",
    "    if epoch%update_freq ==0 and epoch != 0:\n",
    "            print(steer)\n",
    "            print(\"Update with batches:\",len(p.buffer.states))\n",
    "            p.update()\n",
    "            if steer_w > min_steer_w +0.1:\n",
    "                steer_w -= steer_decay\n",
    "    '''\n",
    "    '''\n",
    "    else:\n",
    "            print(total_r,epoch,step)\n",
    "            total_reward_list.append(total_r)\n",
    "            epoch_list.append(epoch)\n",
    "            step_list.append(step)\n",
    "            continue\n",
    "    #except Exception as e:\n",
    "        #print(\"Error:\",e)\n",
    "        #pass\n",
    "    '''\n",
    "    '''\n",
    "    #cv2.destroyAllWindows()\n",
    "    #print(total_r,epoch,step)\n",
    "    #total_reward_list.append(total_r)\n",
    "    #epoch_list.append(epoch)\n",
    "    #step_list.append(step)\n",
    "    '''\n",
    "    print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = prepare_ngsim_scenario(client)\n",
    "ids = list(world.get_actors())[0].id\n",
    "carla.command.DestroyActor(ids)\n",
    "world = client.get_world()\n",
    "#spectator = world.get_spectator()\n",
    "ego_vehicle = prepare_ego_vehicle(world)\n",
    "scenario.reset(ego_vehicle)\n",
    "done = False\n",
    "c = world.tick()\n",
    "way = scenario._veh.transform.as_carla_transform()\n",
    "cmd_buffer = [0]\n",
    "yaw_buffer = [0]\n",
    "stab = False\n",
    "aw = None\n",
    "speed = 60\n",
    "val = 0\n",
    "steer = []\n",
    "brake = []\n",
    "throttle = []\n",
    "step = 0\n",
    "while not done:\n",
    "    pid = VehiclePIDController(ego_vehicle,1.0)\n",
    "    #speed = 90\n",
    "    #print(way.location.x,way.location.y)\n",
    "    k = pid.run_step(speed,way)\n",
    "    #print(k.steer)\n",
    "    if step == 0:\n",
    "        k.steer = -0.1\n",
    "    \n",
    "    steer.append(k.steer)\n",
    "    throttle.append(k.throttle)\n",
    "    brake.append(k.brake)\n",
    "    print(way.location.x,way.location.y)\n",
    "    print(ego_vehicle.get_location().x,ego_vehicle.get_location().y)\n",
    "    ego_vehicle.apply_control(carla.VehicleControl(throttle=k.throttle, steer=np.clip(k.steer,-0.9,0.9), brake = k.brake))\n",
    "    r = scenario.step(ego_vehicle)\n",
    "    print(r.reward,done,r.chauffeur_cmd)\n",
    "    #way = scenario._target_lane_waypoint.transform\n",
    "    val = r.chauffeur_cmd.value\n",
    "    way,speed = way_cal(ego_vehicle,val,scenario)\n",
    "    speed += 10\n",
    "    print(_['on_target_lane'])\n",
    "    #way = r.info[\"scenario_data\"][\"original_veh_transform\"]\n",
    "    cmd_buffer.append(r.chauffeur_cmd.value)\n",
    "    yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "    if len(cmd_buffer) > 10:\n",
    "        if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and sum([abs(x) for x in yaw_buffer[-10:]])/10<=10:\n",
    "            reward = 1 + random.random()/2\n",
    "            done = True\n",
    "    step +=1\n",
    "    birdview = birdview_producer.produce(\n",
    "\n",
    "            agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "            )\n",
    "    rgb = BirdViewProducer.as_rgb(birdview)\n",
    "    cv2.imshow('Frame',rgb)\n",
    "    done = r.done\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "    c = world.tick()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    #scenario.reset(ego_vehicle)\n",
    "    #client.apply_batch([carla.command.DestroyActor(x) for x in list(world.get_actors())])\n",
    "    #world.tick()\n",
    "    ids = list(world.get_actors())[0].id\n",
    "    carla.command.DestroyActor(ids)\n",
    "    world = client.get_world()\n",
    "    #spectator = world.get_spectator()\n",
    "    ego_vehicle = prepare_ego_vehicle(world)\n",
    "    scenario.reset(ego_vehicle)\n",
    "    done = False\n",
    "    c = world.tick()\n",
    "    way = ego_vehicle.get_transform()\n",
    "    cmd_buffer = [0]\n",
    "    yaw_buffer = [0]\n",
    "    stab = False\n",
    "    aw = None\n",
    "    speed = 40\n",
    "    val = 0\n",
    "    while not done:\n",
    "        pid = VehiclePIDController(ego_vehicle,0.9)\n",
    "        speed = random.randint(30,50)\n",
    "        k = pid.run_step(speed,way)\n",
    "        ego_vehicle.apply_control(carla.VehicleControl(throttle=k.throttle, steer=k.steer, brake = k.brake))\n",
    "        r = scenario.step(ego_vehicle)\n",
    "        print(r.reward,done,r.chauffeur_cmd)\n",
    "        #way = scenario._target_lane_waypoint.transform\n",
    "        val = r.chauffeur_cmd.value\n",
    "        way = way_cal(ego_vehicle,val)\n",
    "        #way = r.info[\"scenario_data\"][\"original_veh_transform\"]\n",
    "        cmd_buffer.append(r.chauffeur_cmd.value)\n",
    "        yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "        if len(cmd_buffer) > 10:\n",
    "            if sum(cmd_buffer[-10:]) == 0 and _['on_target_lane'] and sum([abs(x) for x in yaw_buffer[-10:]])/10<=10:\n",
    "                reward = 1 + random.random()/2\n",
    "                done = True\n",
    "\n",
    "        birdview = birdview_producer.produce(\n",
    "\n",
    "                agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "                )\n",
    "        rgb = BirdViewProducer.as_rgb(birdview)\n",
    "        cv2.imshow('Frame',rgb)\n",
    "        done = r.done\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "        c = world.tick()\n",
    "    cv2.destroyAllWindows()\n",
    "    #time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(10).reshape(1,10)\n",
    "b = torch.arange(100).reshape(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((a,b),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decaying:\",p.action_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_['scenario_data']['original_to_ego_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_reward = []\n",
    "val_success = []\n",
    "for i in range(50):\n",
    "    t_clip_n = 0.0\n",
    "    t_clip_p = 1.0\n",
    "\n",
    "    s_clip_n = -1.0\n",
    "    s_clip_p = 1.0\n",
    "\n",
    "    step = 0\n",
    "    scenario = prepare_ngsim_scenario(client,\"Val\")\n",
    "    world = client.get_world()\n",
    "    spectator = world.get_spectator()\n",
    "    ego_vehicle = prepare_ego_vehicle(world)\n",
    "\n",
    "    scenario.reset(ego_vehicle)\n",
    "    c = world.tick()\n",
    "    way = way_cal(ego_vehicle,val)\n",
    "    done = False\n",
    "    reward = 0\n",
    "    val = 0\n",
    "    cmd_buffer = [0]\n",
    "    yaw_buffer = [0]\n",
    "    while not done:\n",
    "\n",
    "            birdview = birdview_producer.produce(\n",
    "                agent_vehicle=ego_vehicle  # carla.Actor (spawned vehicle)\n",
    "                )\n",
    "            #a = birdview[0].reshape(1,186,150)\n",
    "            #a = np.append(a,birdview[1].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[2].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[3].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[4].reshape(1,186,150),axis=0)\n",
    "            #a = np.append(a,birdview[4].reshape(1,224,224),axis=0)\n",
    "            #rgb = BirdViewProducer.as_rgb(birdview)/255.\n",
    "            rgb = BirdViewProducer.as_rgb(birdview)\n",
    "            #in_data = a.reshape(1,5,186,150)\n",
    "            in_data = rgb.reshape(1,3,224,224)/255.\n",
    "\n",
    "            with torch.no_grad():\n",
    "                in_data = torch.FloatTensor(in_data).to(device)\n",
    "                in_data = mobilenet.features(in_data)\n",
    "                in_data = nn.AvgPool2d(7,7)(in_data)\n",
    "                in_data = nn.Flatten()(in_data)\n",
    "                in_data = in_data.detach().cpu().numpy()\n",
    "            #in_data = mdl(in_data).numpy()\n",
    "            #in_data = in_data.reshape(in_data.shape[0],62720)\n",
    "            #in_data = in_data.reshape((1,5,186,150))\n",
    "            #in_data = input_data.reshape((1,3,320,320))\n",
    "            #print(in_data.shape)\n",
    "            if val == 0 or val == 1:\n",
    "                inps= [0,0,1]\n",
    "            if val == 2 or val == 5:\n",
    "                inps = [0,1,0]\n",
    "            if val == 4 or val ==3:\n",
    "                inps = [1,0,0]\n",
    "            inps = np.array(inps)\n",
    "            ap = np.concatenate((in_data[0],inps)).reshape(1,1283)\n",
    "\n",
    "            action = p.select_action(ap)\n",
    "            #print(action)\n",
    "            #action = action*2 - 1\n",
    "            #steer = action[0]\n",
    "            #_speed = np.clip(action[0], -1,1)\n",
    "            #speed = ((_speed + 1)/2)*50 + 10\n",
    "\n",
    "\n",
    "\n",
    "            #pid = VehiclePIDController(ego_vehicle)\n",
    "            #k = pid.run_step(scenario._veh.speed,way)\n",
    "            #throttle = k.throttle\n",
    "            #brake = k.brake\n",
    "            d_action = action_space[action]\n",
    "            \n",
    "            steer = action[1]\n",
    "            avg_steer = steer\n",
    "            throttle = 0.0\n",
    "            brake = 0.0\n",
    "            if d_action[0]<0:\n",
    "                brake = d_action[0]\n",
    "            else:\n",
    "                throttle = d_action[0]\n",
    "            ego_vehicle.apply_control(carla.VehicleControl(throttle=throttle, steer=np.clip(avg_steer, s_clip_n, s_clip_p),brake=brake))\n",
    "\n",
    "            #ego_vehicle.apply_control(carla.VehicleControl(throttle=np.clip(throttle, t_clip_n, t_clip_p), steer=np.clip(action[1], s_clip_n, s_clip_p)))#,brake=np.clip(brake, 0.0, 1.0)))\n",
    "\n",
    "\n",
    "\n",
    "            cmd, reward, done, _ = scenario.step(ego_vehicle)\n",
    "            '''\n",
    "            if reward < 0 :\n",
    "                reward = -0.1\n",
    "            '''\n",
    "\n",
    "\n",
    "\n",
    "            #print(reward, cmd, _['scenario_data']['original_to_ego_distance'], throttle,steer)\n",
    "\n",
    "            val = cmd.value\n",
    "            cmd_buffer.append(val)\n",
    "            yaw_buffer.append(ego_vehicle.get_transform().rotation.yaw)\n",
    "            '''\n",
    "            if len(cmd_buffer) > 5:\n",
    "                if sum(cmd_buffer[-5:]) == 0 and _['on_target_lane'] and abs(yaw_buffer[-1])<=10:\n",
    "                    reward = 1.1\n",
    "                    done = True\n",
    "            '''\n",
    "            \n",
    "            if reward >=0.9:\n",
    "                print(\"Close to win\")\n",
    "            if reward >= 1:\n",
    "                print(\"Its a win\")\n",
    "                #p.save(\"WinModel\"+str(epoch)+\".mdl\")\n",
    "            #way = _[\"scenario_data\"][\"original_veh_transform\"]\n",
    "            way = way_cal(ego_vehicle,val)\n",
    "            #way = scenario._target_lane_waypoint.transform \n",
    "            '''\n",
    "            rgb = BirdViewProducer.as_rgb(birdview)\n",
    "            cv2.imshow('Frame',rgb)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            '''\n",
    "            c = world.tick()\n",
    "    if reward >0.9:\n",
    "        val_reward.append(reward)\n",
    "        val_success.append(1)\n",
    "    else:\n",
    "        val_reward.append(reward)\n",
    "        val_success.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_['on_target_lane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(val_success)/len(val_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_transform().rotation.yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_['scenario_data']['original_veh_transform'].rotation.yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.load(\"Model_CHK_TorchEasy.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.action_std = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.decay_action_std(0.01,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.action_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(2.5e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.reset(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.step(ego_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.get_location().x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle = prepare_ego_vehicle(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.apply_control(carla.VehicleControl(throttle=0.7, steer=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = [epoch_list,total_reward_list,step_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"History00.pkl\",'wb')\n",
    "pickle.dump(History,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(\"Model_Best.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = epoch_list[500:]\n",
    "total_reward_list = total_reward_list[500:]\n",
    "step_list = step_list[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(-2,1)\n",
    "plt.plot(epoch_list,total_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in total_reward_list[400:600]:\n",
    "    if i>0:\n",
    "        count +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "320*320*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = input_data.reshape((1,3,320,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.select_action(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.buffer.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.buffer.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "idx = '2'\n",
    "l = glob.glob('Hm/*.pkl')\n",
    "epoch_list_0 = [] \n",
    "\n",
    "hist = {}\n",
    "for i in l:\n",
    "    f = open(i,'rb')\n",
    "    s = pickle.load(f)\n",
    "    f.close()\n",
    "    n = i.split('/')[1]\n",
    "    n = n.split('.')[0]\n",
    "    n = n.split('_')\n",
    "    if n[2] in hist.keys():\n",
    "        pass\n",
    "    else:\n",
    "        hist[n[2]] = {}\n",
    "    hist[n[2]][n[1]] = s \n",
    "    \n",
    "for i in sorted([int(x) for x in hist[idx].keys()]):\n",
    "    epoch_list_0 += hist[idx][str(i)][0]\n",
    "reward_list_0 = []\n",
    "\n",
    "for i in sorted([int(x) for x in hist[idx].keys()]):\n",
    "    reward_list_0 += hist[idx][str(i)][1]\n",
    "step_list_0 = []\n",
    "for i in sorted([int(x) for x in hist[idx].keys()]):\n",
    "    step_list_0 += hist[idx][str(i)][2]\n",
    "final_epoch_list = epoch_list_0\n",
    "final_reward_list = reward_list_0\n",
    "final_step_list = step_list_0\n",
    "val_list = []\n",
    "ep_list = []\n",
    "for i in sorted([int(x) for x in hist[idx].keys()]):\n",
    "    ep_list.append(i)\n",
    "    val_list.append(hist[idx][str(i)][3])\n",
    "epochs = list(range(len(val_list)))\n",
    "ids =sorted([int(x) for x in hist[idx].keys()])\n",
    "train_score = []\n",
    "average_train = []\n",
    "for i in epochs:\n",
    "    c = ids[i]\n",
    "    arr = hist[idx][str(c)][1]\n",
    "    count = 0\n",
    "    sme = 0\n",
    "    for j in arr:\n",
    "        sme += j\n",
    "        if j >0:\n",
    "            count+=1\n",
    "    average_train.append(sme/len(arr))\n",
    "    train_score.append(count/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Reward Sum\")\n",
    "plt.plot(final_epoch_list,final_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Step size\")\n",
    "plt.plot(final_epoch_list,final_step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(0,1.0)\n",
    "#plt.xlim(0,5000)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"success rate\")\n",
    "plt.plot(epochs,train_score)\n",
    "plt.plot(epochs,val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.xlim(0,3000)\n",
    "#plt.ylim(-1,1)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"TrainRewardAvg\")\n",
    "plt.plot(epochs,average_train)\n",
    "#plt.plot(epochs,val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([int(x) for x in hist[idx].keys()])[172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs[172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list[172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list[150:200][20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score[150:200][20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buff = [True,True,False,True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(item == True for item in buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = glob.glob('He/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = {}\n",
    "for i in l:\n",
    "    f = open(i,'rb')\n",
    "    s = pickle.load(f)\n",
    "    f.close()\n",
    "    n = i.split('/')[1]\n",
    "    n = n.split('.')[0]\n",
    "    n = n.split('_')\n",
    "    if n[2] in hist.keys():\n",
    "        pass\n",
    "    else:\n",
    "        hist[n[2]] = {}\n",
    "    hist[n[2]][n[1]] = s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('w','2000') in hist.keys():\n",
    "    print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list_0 = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted([int(x) for x in hist['0'].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted([int(x) for x in hist['2'].keys()]):\n",
    "    epoch_list_0 += hist['2'][str(i)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['0']['500'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_list_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list_0 = []\n",
    "\n",
    "for i in sorted([int(x) for x in hist['2'].keys()]):\n",
    "    reward_list_0 += hist['2'][str(i)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list_0 = []\n",
    "for i in sorted([int(x) for x in hist['2'].keys()]):\n",
    "    step_list_0 += hist['2'][str(i)][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list_1 = []\n",
    "for i in sorted([int(x) for x in hist['1'].keys()]):\n",
    "    epoch_list_1 += hist['1'][str(i)][0]\n",
    "reward_list_1 = []\n",
    "for i in sorted([int(x) for x in hist['1'].keys()]):\n",
    "    reward_list_1 += hist['1'][str(i)][1]\n",
    "step_list_1 = []\n",
    "for i in sorted([int(x) for x in hist['1'].keys()]):\n",
    "    step_list_1 += hist['1'][str(i)][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch_list = epoch_list_0 + [x + len(epoch_list_0) for x in epoch_list_1]\n",
    "final_reward_list = reward_list_0 + reward_list_1\n",
    "final_step_list = step_list_0 + step_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch_list = epoch_list_0\n",
    "final_reward_list = reward_list_0\n",
    "final_step_list = step_list_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_epoch_list))\n",
    "print(len(final_reward_list))\n",
    "len(final_step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Reward Sum\")\n",
    "plt.plot(final_epoch_list,final_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Step size\")\n",
    "plt.plot(final_epoch_list,final_step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([int(x) for x in hist['1'].keys()])[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(hist['0'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = []\n",
    "ep_list = []\n",
    "for i in sorted([int(x) for x in hist['2'].keys()]):\n",
    "    ep_list.append(i)\n",
    "    val_list.append(hist['2'][str(i)][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(len(val_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0,1.0)\n",
    "#plt.xlim(0,5000)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"success rate\")\n",
    "plt.plot(epochs,train_score)\n",
    "plt.plot(epochs,val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0,1.0)\n",
    "#plt.xlim(0,5000)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"success rate\")\n",
    "plt.plot(epochs,train_score)\n",
    "plt.plot(epochs,val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids =sorted([int(x) for x in hist['2'].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['0'][str(c)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "\n",
    "for i in epochs:\n",
    "    c = ids[i]\n",
    "    arr = hist['2'][str(c)][1]\n",
    "    count = 0\n",
    "    for j in arr:\n",
    "        if j >0:\n",
    "            count+=1\n",
    "    train_score.append(count/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[310:320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list[310:330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(epoch_list).reshape(-1,1),np.array(total_reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(0,7000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(np.array(x).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = epoch_list\n",
    "y= total_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Rewards\")\n",
    "plt.ylim(-2.0,2.0)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.ylim(0.0,10.0)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"History_5500_1.pkl\",'rb')\n",
    "s = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = s[0]\n",
    "r = s[1]\n",
    "t = s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
